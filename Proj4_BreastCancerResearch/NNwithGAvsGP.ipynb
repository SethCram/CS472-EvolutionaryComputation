{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Seth Cram\n",
    "Class: Evolutionary Computation - CS472/CS572\n",
    "\n",
    "Project 4\n",
    "\n",
    "Due Date: Dec 9, 2022\n",
    "\n",
    "Instructions:\n",
    "\n",
    "You should read the page and familiarize yourself with the way the data\n",
    "is formatted. Note that not all the data should be used when training your classifiers, you should select part of the data to be used to train your neural network/GP, part of the data should be reserved as a validation set.\n",
    "\n",
    "Submission information:\n",
    "\n",
    "You should construct a document where you describe your dataset, and how you had to modify or clean the dataset. You should describe the goal of the classification, why it is important, and what makes classifying the data challenging. Try to describe the search space, but note that in real world datasets, it isn't always obvious what range of values exist.\n",
    "\n",
    "Describe your algorithms. Describe all methods you used to classify the data, and descriptions of any diversity techniques you use.\n",
    "\n",
    "Plot and describe your results and any conclusions you can make from the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Cells\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/SethCram/CS472-EvolutionaryComputation/blob/master/Proj4_BreastCancerResearch/NNwithGAvsGP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Google Colab Cell\n",
    "\n",
    "#enable debugging\n",
    "!pip install -Uqq ipdb\n",
    "import ipdb\n",
    "%pdb on\n",
    "\n",
    "#mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "#for Seth google act\n",
    "#%cd /content/drive/MyDrive/School/Senior Year/CS 472-01 (Evolutionary Computation)/Project4/\n",
    "#for other google act\n",
    "%cd /content/drive/MyDrive/EC-Proj4/\n",
    "\n",
    "#make sure GPU enabled\n",
    "!nvidia-smi\n",
    "\n",
    "!pip install anytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import losses\n",
    "#GP imports\n",
    "import copy\n",
    "from enum import Enum\n",
    "import scipy.stats as ss\n",
    "import anytree\n",
    "from functools import reduce\n",
    "import operator as OPER\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "#NN+GA imports \n",
    "import keras \n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import activations\n",
    "from keras import applications\n",
    "import random\n",
    "#from deepdiff import DeepDiff\n",
    "\n",
    "print(\"modules imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the alzheimers dataset\n",
    "def load_data(test_split = 0.3, validation_split = 0.2):\n",
    "    \n",
    "    ## (1) Data preparation\n",
    "    df=pd.read_csv('AlzData.csv', sep = ',')\n",
    "    print(df)\n",
    "    \n",
    "    # rm ids, rm targets\n",
    "    transposedDataFrameVals = df.values.T[1:-1].astype('float32')\n",
    "    #walk thru features\n",
    "    for i, row in enumerate(transposedDataFrameVals):\n",
    "        #normalize data [0,1]\n",
    "        transposedDataFrameVals[i] = row / max(row)\n",
    "    \n",
    "    #assign normalized data\n",
    "    X = transposedDataFrameVals.T\n",
    "    \n",
    "    #assign targets\n",
    "    targets = df.values.T[-1]\n",
    "    #conv to binary target\n",
    "    Y = np.array( [1 if target == 'P' else 0 for target in targets] )\n",
    "    \n",
    "    print(f'After normalization, X max = {max(X.flatten())}, X min = {min(Y.flatten())}')\n",
    "\n",
    "    # data split of 70 training and 30 test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_split)\n",
    "        \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_data()\n",
    "\n",
    "print('Data shape:', 'x_train:', x_train.shape, 'x_test:', x_test.shape)\n",
    "print('Data shape:', 'y_train:', y_train.shape, 'y_test:', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enum Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestType(Enum):\n",
    "    TRAINING = 0\n",
    "    VALIDATION = 1\n",
    "    TEST = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filePath) -> None:\n",
    "    with open(filePath, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def restore_object(filePath):\n",
    "    with open(filePath, 'rb') as inp:\n",
    "        obj = pickle.load(inp)\n",
    "        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IF(ops):\n",
    "    conditional, trueRslt, falseRslt = ops[0], ops[1], ops[2]\n",
    "    \n",
    "    #print(f\"if({conditional}) then {trueRslt} else {falseRslt}\")\n",
    "    \n",
    "    if conditional:\n",
    "        return trueRslt\n",
    "    else:\n",
    "        return falseRslt\n",
    " \n",
    "def SUBTRACT(ops):\n",
    "    #print(f\"{ops[0]} - {ops[1]}\")\n",
    "    \n",
    "    return reduce(OPER.sub, ops)\n",
    "\n",
    "def MULTIPLY(ops):\n",
    "    #print(f\"{ops[0]} * {ops[1]}\")\n",
    "    \n",
    "    return reduce(OPER.mul, ops)\n",
    "    \n",
    "def DIVIDE(ops):\n",
    "    \"\"\"Protected divison\n",
    "\n",
    "    Args:\n",
    "        ops (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(f\"{ops[0]} / {ops[1]}\")\n",
    "    \n",
    "    if( ops[1] == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return ops[0] / ops[1]\n",
    "    \n",
    "class Operator():\n",
    "    def __init__(self, funct, arity) -> None:\n",
    "        self.funct = funct\n",
    "        self.arity = arity\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.funct}, arity {self.arity}\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.funct}, arity {self.arity}\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enum Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitType(Enum):\n",
    "    GROWTH = 0\n",
    "    FULL = 1\n",
    "    \n",
    "class NodeType(Enum):\n",
    "    TERMINAL = 0\n",
    "    NONTERMINAL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Individual():\n",
    "    def __init__(self, initDepth: int, initType: InitType, NT: set, T: set, x, y, softCapNodeMax) -> None:\n",
    "        #var init\n",
    "        self.initType = initType\n",
    "        self.initDepth = initDepth\n",
    "        self.T = T\n",
    "        self.NT = NT\n",
    "        self.softCapNodeMax = softCapNodeMax\n",
    "        \n",
    "        assert len(x) == len(y)\n",
    "        \n",
    "        #funct init\n",
    "        \n",
    "        #initialize individual as tree\n",
    "        self.nodeIndex = 0\n",
    "        self.root = self.CreateNodeNT(self.nodeIndex, parent=None)\n",
    "        self.CreateTreeRecursively(self.root)\n",
    "        #print(anytree.RenderTree(self.root))\n",
    "        \n",
    "        assert self.nodeIndex == self.GetNodeCount() - 1\n",
    "        #print(f\"self node count = {self.nodeCount}, get node count = {self.GetNodeCount()}\")\n",
    "        \n",
    "        #fitness eval of tree\n",
    "        self.EvaluateFitness(x, y)\n",
    "       \n",
    "    def EvaluateFitness(self, x, y, applyParsimonyPressure = True):\n",
    "        \"\"\"\n",
    "        Fitness evaluated through using RMSE (Root Mean Sqrd Error).\n",
    "        Applies parsimony pressure by default.\n",
    "        Lower fitness is better.\n",
    "        \"\"\"\n",
    "        \n",
    "        #predict the output class prob given input\n",
    "        y_prob_pred = self.Predict_Prob(x)\n",
    "        \n",
    "        #sum up how many are wrong (more wrong, worse fitness)\n",
    "        #fitness = sum( y_pred != y )\n",
    "        \n",
    "        #sum up bin cross entropy loss of each pred\n",
    "        fitness = losses.binary_crossentropy(y_pred=y_prob_pred, y_true=y).numpy()#sum()\n",
    "        \n",
    "        nodeCount = self.GetNodeCount()\n",
    "            \n",
    "        #if applying pressure and enough nodes to apply fitness mod\n",
    "        if applyParsimonyPressure and nodeCount > self.softCapNodeMax:\n",
    "            #incr fitness by every additional node over the max\n",
    "            fitness = fitness * (nodeCount / self.softCapNodeMax)\n",
    "            \n",
    "        self.fitness = fitness\n",
    "    \n",
    "    def Predict_Prob(self, x) -> list:\n",
    "        participantCount = x.shape[0]\n",
    "        #inputCount = x.shape[1]\n",
    "        \n",
    "        y_pred_prob = np.empty(participantCount)\n",
    "        \n",
    "        #walk down every col\n",
    "        for j in range(participantCount):\n",
    "            #walk across every row\n",
    "            #for i in range(inputCount):\n",
    "            #NT's assigned values\n",
    "            self.EvaluateFitnessRecursively(self.root, x[j])\n",
    "            #store each input value's output\n",
    "            #y_tree_pred[j][i] = self.root.value\n",
    "            y_pred_prob[j] = self.root.value\n",
    "                \n",
    "        #average outputs of tree for each row into a single output\n",
    "        #y_pred_prob = np.sum( y_tree_pred, axis=1) / inputCount\n",
    "            \n",
    "        #make sure each tree output is normalized [0, 1]\n",
    "        #if (max( y_tree_pred.flatten() ) > 1.1 or\n",
    "        #    min( y_tree_pred.flatten() < -0.1)):\n",
    "        #y_pred_prob = sklearn.preprocessing.minmax_scale(y_pred_prob, feature_range=(0, 1), axis=0, copy=True) #dont need axis anymore\n",
    "        y_pred_prob = sklearn.preprocessing.minmax_scale(y_pred_prob, feature_range=(0, 1), copy=True)\n",
    "        \n",
    "        return y_pred_prob\n",
    "    \n",
    "    def Predict(self, x) -> list:\n",
    "        \"\"\"Predict output given inputs.\n",
    "        Averages outputs across each row.x_train\n",
    "        Normalization performed if average not [0, 1]\n",
    "\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            list: _description_\n",
    "        \"\"\"\n",
    "        #predict each class's probability\n",
    "        y_pred_prob = self.Predict_Prob(x)\n",
    "        \n",
    "        #round outputs to binary output (rounds down)\n",
    "        y_pred = np.round(y_pred_prob) \n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def EvaluateFitnessRecursively(self, parent: anytree.node, x: float):\n",
    "        \"\"\"NT nodes assigned values.\n",
    "\n",
    "        Args:\n",
    "            parent (anytree.node): _description_\n",
    "        \"\"\"\n",
    "        ops = []\n",
    "        #walk thru children\n",
    "        for child in parent.children:\n",
    "            #if child is NT and not evaluated\n",
    "            if (child.type == NodeType.NONTERMINAL):\n",
    "                #evaluate child (don't change input val)\n",
    "                self.EvaluateFitnessRecursively(child, x)\n",
    "            #if child val is a variable \n",
    "            if( type(child.value) == str and child.value[0] == 'x'): # child.value == 'x'\n",
    "                #substitute passed in var's attribute\n",
    "                ops.append(x[int(child.value[1:])])\n",
    "            #regular child \n",
    "            else:\n",
    "                ops.append(child.value)\n",
    "        \n",
    "        #evaluate parent using children values\n",
    "        parent.value = float( parent.operator.funct(ops) )\n",
    "       \n",
    "    def CreateTreeRecursively(self, parent: anytree.Node) -> None:\n",
    "            #every parent is a NT\n",
    "            for _ in range(parent.operator.arity):\n",
    "                self.nodeIndex += 1\n",
    "                nodeName = self.nodeIndex\n",
    "                \n",
    "                #if creating laster layer of nodes\n",
    "                if parent.depth == self.initDepth - 2: #depth starts at 0\n",
    "                        #create T node\n",
    "                        self.CreateNodeT(nodeName, parent) \n",
    "                #if not creating last layer\n",
    "                else:\n",
    "                    if self.initType == InitType.FULL:\n",
    "                        #recursively create NT\n",
    "                        self.CreateTreeRecursively( self.CreateNodeNT(nodeName, parent) )\n",
    "                    elif self.initType == InitType.GROWTH:\n",
    "                        #roll a 50/50 on whether child is T or NT\n",
    "                        if np.random.randint(0,2) == 0:\n",
    "                            #recursively create NT\n",
    "                            self.CreateTreeRecursively( self.CreateNodeNT(nodeName, parent) )\n",
    "                        else:\n",
    "                            self.CreateNodeT(nodeName, parent)\n",
    "              \n",
    "    def CreateNodeNT(self, nodeName, parent) -> anytree.Node:\n",
    "        #create a NT child node\n",
    "        return anytree.Node(nodeName, \n",
    "            operator=random.choice(tuple(self.NT)),\n",
    "            type = NodeType.NONTERMINAL,  \n",
    "            value = 0,                                   \n",
    "            parent = parent\n",
    "        )\n",
    "    \n",
    "    def CreateNodeT(self, nodeName, parent) -> anytree.Node:\n",
    "        #create a T child node\n",
    "        return anytree.Node(nodeName, \n",
    "            value = random.choice(tuple(self.T)), \n",
    "            type = NodeType.TERMINAL, \n",
    "            parent = parent\n",
    "        )\n",
    "       \n",
    "    def GetNodeCount(self) -> int:\n",
    "        \"\"\"Calcs node count through counting the root's descendants.\n",
    "        Needs to dynamically calculate node count bc during crossover, tree size changes.\n",
    "\n",
    "        Returns:\n",
    "            int: _description_\n",
    "        \"\"\"\n",
    "        #return number of descendants and 1 to account for root\n",
    "        return len(self.root.descendants) + 1\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{anytree.RenderTree(self.root)}, fitness of {self.fitness}\"  \n",
    "\n",
    "def getFitness( individual: Individual ) -> int:\n",
    "    return individual.fitness\n",
    "\n",
    "_NT = {\n",
    "        Operator(funct=sum, arity=2), \n",
    "        Operator(funct=SUBTRACT, arity=2), \n",
    "        Operator(funct=MULTIPLY, arity=2), \n",
    "        Operator(funct=DIVIDE, arity=2), #division by zero always yields zero in integer arithmetic.\n",
    "        Operator(funct=np.abs, arity=1),\n",
    "        Operator(funct=IF, arity=3),\n",
    "        Operator(funct=np.sin, arity=1),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "#construct terminal set\n",
    "# one x for every attribute\n",
    "_T = set([ 'x' + str(i) for i in range(x_test.shape[1])])\n",
    "_T.update({0, 1, 1.4, 3, 18, np.pi})\n",
    "\n",
    "_y_train = y_train[0:10]\n",
    "_x_train = x_train[0:10]\n",
    "_y_test = y_test[0:10]\n",
    "_x_test = x_test[0:10]\n",
    "\n",
    "#test individual class (initDepth of 4)\n",
    "individual1 = Individual(4, InitType.FULL, _NT, _T, _x_train, _y_train, softCapNodeMax=10)\n",
    "individual2 = Individual(4, InitType.GROWTH, _NT, _T, _x_train, _y_train, softCapNodeMax=10)\n",
    "\n",
    "#Parsimony pressure testing\n",
    "print(f\"fitness: {individual1.fitness}, node count: {individual1.GetNodeCount()}\")\n",
    "print(f\"fitness: {individual2.fitness}, node count: {individual2.GetNodeCount()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP():\n",
    "    \"\"\"\n",
    "    Genetic Program with individuals as trees.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        populationSize: int, \n",
    "        initDepth: int, \n",
    "        NT: set, \n",
    "        T: set, \n",
    "        x_train, \n",
    "        y_train, \n",
    "        pairs_of_parents_elitism_saves, \n",
    "        #island_model = False,\n",
    "        migration_interval: int = 5,\n",
    "        migration_size: int = 0,\n",
    "        softCapNodeMax: int = 10, \n",
    "        xrate: float = 1\n",
    "    ):\n",
    "        self.populationSize = populationSize\n",
    "        self.localPopulationSize = populationSize - migration_size\n",
    "        self.initDepth = initDepth\n",
    "        self.NT = NT\n",
    "        self.T = T\n",
    "        self.xrate = xrate\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        #self.selectionType\n",
    "        self.currentGeneration = 0\n",
    "        self.pairs_of_parents_elitism_saves = pairs_of_parents_elitism_saves\n",
    "        self.migration_size = migration_size\n",
    "        self.migration_interval = migration_interval\n",
    "        self.testPerformance = 0\n",
    "        self.trainingPerformance = 0\n",
    "        \n",
    "        #create pop of 50/50 growth/full individuals\n",
    "        self.localPopulation = [\n",
    "                Individual(initDepth, InitType.FULL, NT, T, x_train, y_train, softCapNodeMax) \n",
    "                for _ in range(int(self.localPopulationSize/2))\n",
    "            ] + [\n",
    "                Individual(initDepth, InitType.GROWTH, NT, T, x_train, y_train, softCapNodeMax) \n",
    "                for _ in range(int(self.localPopulationSize/2))\n",
    "            ] \n",
    "        \n",
    "        #needed for migration pop creation\n",
    "        #assert self.migration_size > 3\n",
    "        \n",
    "        #can't have more immigrants than pop size\n",
    "        assert self.populationSize > migration_size\n",
    "            \n",
    "        self.population = self.localPopulation #could just be empty list\n",
    "        self.recievedMigrants = []\n",
    "        self.sentMigrants = []\n",
    "        \n",
    "        #init fitness lists w/ starting pop's fitness vals\n",
    "        self.avgFitness = [] #[self.GetAvgFitness()]\n",
    "        self.bestFitness = [] #[self.GetBestFitness()]\n",
    "        self.worstFitness = [] #[self.GetWorstFitness()] \n",
    "        self.bestFitnessNodeCount = [] #[self.GetBestFitnessNodeCount()]\n",
    "        self.worstFitnessNodeCount = [] #[self.GetWorstFitnessNodeCount()]\n",
    "           \n",
    "    def GetMigrants(self) -> list:\n",
    "        #if on a migration interval\n",
    "        if self.currentGeneration % self.migration_interval == 0:\n",
    "            #update migrant pop \n",
    "            self.sentMigrants = []\n",
    "            #fitness prop individuals\n",
    "            #fitnessPropIndiv1, fitnessPropIndiv2 = self.SelectParents() \n",
    "            #add best fit individual\n",
    "            self.sentMigrants.append( self.GetBestFitIndividual() )\n",
    "            #add fitness prop parents\n",
    "            #self.sentMigrants.append( fitnessPropIndiv1 )\n",
    "            #self.sentMigrants.append( fitnessPropIndiv2 )\n",
    "            #add rest of migration pop as random individuals \n",
    "            for _ in range(len(self.sentMigrants), self.migration_size):\n",
    "                self.sentMigrants.append( self.population[random.randint(1, len(self.population)-1)] ) #should randos be drawn from actual pop or local pop?\n",
    "            \n",
    "        return self.sentMigrants\n",
    "         \n",
    "    def RecvMigrants(self, migrants) -> None:\n",
    "        self.recievedMigrants = migrants\n",
    "        \n",
    "        #combine local pop + migrant pop to create island pop\n",
    "        self.population = self.localPopulation + self.recievedMigrants\n",
    "        \n",
    "    def RunGen(self) -> None:\n",
    "        #if first gen\n",
    "        if self.currentGeneration == 0:\n",
    "            #correct init pops fitness fields\n",
    "            self.avgFitness.append( self.GetAvgFitness() ) \n",
    "            self.worstFitness.append( self.GetWorstFitness() ) \n",
    "            self.bestFitness.append( self.GetBestFitness() )\n",
    "            self.bestFitnessNodeCount.append(self.GetBestFitnessNodeCount())\n",
    "            self.worstFitnessNodeCount.append(self.GetWorstFitnessNodeCount())\n",
    "        \n",
    "        #create new pop\n",
    "        self.CreateNextGeneration()\n",
    "        \n",
    "        #store newly created pops fitness fields\n",
    "        self.avgFitness.append( self.GetAvgFitness() ) \n",
    "        self.worstFitness.append( self.GetWorstFitness() ) \n",
    "        self.bestFitness.append( self.GetBestFitness() )\n",
    "        self.bestFitnessNodeCount.append(self.GetBestFitnessNodeCount())\n",
    "        self.worstFitnessNodeCount.append(self.GetWorstFitnessNodeCount())\n",
    "        \n",
    "        #advance gen count\n",
    "        self.currentGeneration += 1\n",
    "   \n",
    "    def CreateNextGeneration(self) ->None:\n",
    "        #ensure individuals sorted in ascending order\n",
    "        self.OrderPopulationByFitness()\n",
    "        #new pop\n",
    "        newPopulation = []\n",
    "        \n",
    "        #Save parents for elitism \n",
    "        for k in range(0, self.pairs_of_parents_elitism_saves):\n",
    "            newPopulation.append(self.population[k])\n",
    "            newPopulation.append(self.population[k+1])\n",
    "        \n",
    "        pairs_of_children = int(self.localPopulationSize/2)\n",
    "        \n",
    "        #walk thru half pop\n",
    "        for _ in range(self.pairs_of_parents_elitism_saves, pairs_of_children):\n",
    "            #select parents\n",
    "            parent1, parent2 = self.SelectParents()\n",
    "            #do crossover\n",
    "            child1, child2, xover = self.Crossover(parent1, parent2, self.xrate)\n",
    "            #if crossover happened\n",
    "            if(xover):\n",
    "                #re'eval children fitness\n",
    "                child1.EvaluateFitness(self.x_train, self.y_train)\n",
    "                child2.EvaluateFitness(self.x_train, self.y_train)\n",
    "            #add new children to next gen pop\n",
    "            newPopulation.append(child1)\n",
    "            newPopulation.append(child2)\n",
    "            \n",
    "        self.localPopulation = newPopulation\n",
    "            \n",
    "        #don't needa deep copy bc newPopulation wiped out w/ leave funct\n",
    "        \n",
    "        self.population = self.localPopulation + self.recievedMigrants\n",
    "   \n",
    "    def GetBestFitIndividual(self) -> Individual:\n",
    "        return min( self.population, key=getFitness )\n",
    "    \n",
    "    def GetWorstFitIndividual(self) -> Individual:\n",
    "        return max( self.population, key=getFitness )\n",
    "   \n",
    "    def GetBestFitnessNodeCount(self) -> int:\n",
    "        return self.GetBestFitIndividual().GetNodeCount()\n",
    "    \n",
    "    def GetWorstFitnessNodeCount(self) -> int:\n",
    "        return self.GetWorstFitIndividual().GetNodeCount()\n",
    "   \n",
    "    def GetBestFitness(self) -> float:\n",
    "        return self.GetBestFitIndividual().fitness\n",
    "    \n",
    "    def GetWorstFitness(self) -> float:\n",
    "        return self.GetWorstFitIndividual().fitness\n",
    "    \n",
    "    def GetAvgFitness(self) -> float:\n",
    "        fitnessSum = 0\n",
    "        for i in range(0, len(self.population)):\n",
    "            #take the fitness sum\n",
    "            fitnessSum +=  self.population[i].fitness\n",
    "        \n",
    "        return fitnessSum / self.populationSize\n",
    "    \n",
    "    def Crossover(self, parent1: Individual, parent2: Individual, xrate: float = 1) -> tuple:\n",
    "        \"\"\"Swaps subtree parents at their xpoints. \n",
    "        Xpoints gauss centered around last leaf.\n",
    "        Never chooses the root node to do crossover with.\n",
    "\n",
    "        Args:\n",
    "            parent1 (Individual): _description_\n",
    "            parent2 (Individual): _description_\n",
    "\n",
    "        Returns:\n",
    "            tuple: child1, child2, whether xover happened\n",
    "        \"\"\"\n",
    "        \n",
    "        #clone children from parents\n",
    "        child1 = copy.deepcopy(parent1) \n",
    "        child2 = copy.deepcopy(parent2)\n",
    "        \n",
    "        #roll on whether to do crossover\n",
    "        randProb = np.random.random()\n",
    "        xover = randProb <= xrate\n",
    "        if( xover ):\n",
    "        \n",
    "            #pick crossover subtress\n",
    "            parent1subtree, parent2subtree = self.GetCrossoverSubtrees(child1, child2)\n",
    "            \n",
    "            #swap subtree parents (don't copy)\n",
    "            parent1subtree_parent_ph = parent1subtree.parent \n",
    "            #print(anytree.RenderTree(child1.root))\n",
    "            #print(anytree.RenderTree(child2.root))\n",
    "            parent1subtree.parent = parent2subtree.parent\n",
    "            parent2subtree.parent = parent1subtree_parent_ph\n",
    "            #print(anytree.RenderTree(child1.root))\n",
    "            #print(anytree.RenderTree(child2.root))\n",
    "\n",
    "        return child1, child2, xover\n",
    "    \n",
    "    def GetCrossoverSubtrees(self, parent1, parent2) -> tuple:\n",
    "        \"\"\"Swaps subtrees at last leaf gauss random indices.\n",
    "\n",
    "        Args:\n",
    "            parent1 (_type_): _description_\n",
    "            parent2 (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            tuple: child1, child2 still connected to parent1 and parent2 (not copies)\n",
    "        \"\"\"\n",
    "        \n",
    "        #cache parent node counts\n",
    "        p1Nodes = parent1.GetNodeCount()\n",
    "        p2Nodes = parent2.GetNodeCount()\n",
    "        #find descendant node count\n",
    "        p1descendantNodes = p1Nodes - 1\n",
    "        p2descendantNodes = p2Nodes - 1\n",
    "        \n",
    "        #gen half-normal range of ints centered at 0\n",
    "        # std dev of 1/4 of descendant nodes count\n",
    "        p1xIndexRange, p1prob = self.SetupHalfNormIntDistr(p1descendantNodes, stdDev=p1descendantNodes/4)\n",
    "        p2xIndexRange, p2prob = self.SetupHalfNormIntDistr(p2descendantNodes, stdDev=p2descendantNodes/4)\n",
    "        \n",
    "        #sel parent xpoints from 1 to descendant nodes count\n",
    "        p1_xpoint = int( np.random.choice(p1xIndexRange+1, size = 1, p = p1prob) )\n",
    "        p2_xpoint = int( np.random.choice(p2xIndexRange+1, size = 1, p = p2prob) )\n",
    "        \n",
    "        #apply xpoint, starting from the end\n",
    "        # so norm distr centered around end of list (more terminals, smaller NTs)\n",
    "        parent1subtree = parent1.root.descendants[-p1_xpoint]\n",
    "        parent2subtree = parent2.root.descendants[-p2_xpoint]\n",
    "        \n",
    "        #debug: print(f\"Crossover at {parent1subtree.name} and {parent2subtree.name}\")\n",
    "        \n",
    "        assert parent1subtree != None, f\"Couldn't find a node with xpoint {-p1_xpoint-1} in tree {anytree.RenderTree(parent1.root)}\"\n",
    "        assert parent2subtree != None, f\"Couldn't find a node with xpoint {-p2_xpoint-1} in tree {anytree.RenderTree(parent2.root)}\"\n",
    "        \n",
    "        return parent1subtree, parent2subtree\n",
    "    \n",
    "    def SelectParents(self) -> tuple:\n",
    "        xIndexRange, prob = self.SetupHalfNormIntDistr(self.populationSize, stdDev=self.populationSize/3)\n",
    "        \n",
    "        popSize = len(self.population)\n",
    "        if popSize != self.populationSize:\n",
    "            raise IndexError\n",
    "    \n",
    "        #if overloaded to display distr graph\n",
    "        if(False):\n",
    "            #take randos using the calc'd prob and index range\n",
    "            nums = np.random.choice(xIndexRange, size = 1000000, p = prob)\n",
    "            #display distr histogram\n",
    "            plt.rcParams.update({'font.size': 22})\n",
    "            plt.hist(nums, bins = pop_size)\n",
    "            plt.title(\"likelihood of each parent index being chosen\")\n",
    "            plt.ylabel(\"likelihood of being chosen\")\n",
    "            plt.xlabel(\"parent index\")\n",
    "            plt.show()\n",
    "\n",
    "        #get parent indices\n",
    "        parent1Index, parent2Index = np.random.choice(xIndexRange, size = 2, p = prob)\n",
    "        #parent1Index, parent2Index = parentIndices[0], parentIndices[1]\n",
    "        \n",
    "        #make sure indices within array range\n",
    "        assert parent1Index < self.populationSize and parent2Index < self.populationSize, f\"curr pop size = {popSize}, p1 = {parent1Index}, p2 = {parent2Index}\"\n",
    "    \n",
    "        return self.population[int(parent1Index)], self.population[int(parent2Index)]\n",
    "    \n",
    "    def SetupHalfNormIntDistr(self, pop_size: int, stdDev: int) -> tuple:\n",
    "        \"\"\"\n",
    "        The half normal integer distribution parent indices are drawn from.\n",
    "\n",
    "        Returns:\n",
    "            tuple: index range and probability funct\n",
    "        \"\"\"\n",
    "        #take interval 1-100\n",
    "        x = np.arange(1, pop_size+1) #bc upper bound is exclusive\n",
    "        #store every number's +/-0.5\n",
    "        xU, xL = x + 0.5, x - 0.5 \n",
    "        #determine probability\n",
    "        prob = ss.halfnorm.cdf(xU, scale = stdDev) - ss.halfnorm.cdf(xL, scale = stdDev) #scale represents inner quartiles\n",
    "        prob = prob / prob.sum() # normalize the probabilities so their sum is 1\n",
    "        #decr by 1 to find the index 0-99\n",
    "        xIndexRange = x - 1\n",
    "    \n",
    "        return xIndexRange, prob\n",
    "    \n",
    "    def OrderPopulationByFitness(self):\n",
    "        #sort in descending order\n",
    "        self.population.sort(key=getFitness)\n",
    "    \n",
    "    def PlotGenerationalFitness(self):\n",
    "        t = np.arange(0, self.currentGeneration+1)\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 22})\n",
    "        plt.title('Generational Fitness Data')\n",
    "        plt.plot(t, self.worstFitness, label='Worst Fitness') \n",
    "        plt.plot(t, self.avgFitness, label='Average Fitness') \n",
    "        plt.plot(t, self.bestFitness, label='Best Fitness') \n",
    "        plt.grid() \n",
    "        plt.legend()\n",
    "        plt.ylabel('Fitness')\n",
    "        plt.xlabel('Generation')\n",
    "        \n",
    "        #init worst worst fit\n",
    "        worstWorstFitness = max(self.worstFitness)\n",
    "        \n",
    "        fitnessIndex = 0\n",
    "        \n",
    "        for fitnessData in (self.worstFitness, self.avgFitness, self.bestFitness):\n",
    "            yAnnotatePosition = worstWorstFitness - worstWorstFitness * fitnessIndex / 12\n",
    "            \n",
    "            fitnessIndex += 1\n",
    "            \n",
    "            plt.annotate('%0.7f' % min(fitnessData), xy=(1, yAnnotatePosition), xytext=(8, 0), \n",
    "                        xycoords=('axes fraction', 'data'), textcoords='offset points')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def PlotGenerationalNodeCount(self):\n",
    "        t = np.arange(0, self.currentGeneration+1)\n",
    "            \n",
    "        plt.rcParams.update({'font.size': 22})\n",
    "        plt.plot(t, self.bestFitnessNodeCount, label='Best Fitness') \n",
    "        plt.plot(t, self.worstFitnessNodeCount, label='Worst Fitness')\n",
    "        plt.grid() \n",
    "        plt.legend()\n",
    "        plt.title('Node Count per Generation')\n",
    "        plt.ylabel('Node Count')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.show()\n",
    "    \n",
    "    def Test(self, x, y, testType: TestType):\n",
    "        \n",
    "        inputCount = len(x)\n",
    "        \n",
    "        outputCount = len(y)\n",
    "        \n",
    "        assert inputCount == outputCount\n",
    "        \n",
    "        #for i in range(self.populationSize): #why re-eval fitness for new data??\n",
    "        #    self.population[i].EvaluateFitness(x, y)\n",
    "            \n",
    "        bestFitIndividual = self.GetBestFitIndividual()\n",
    "        \n",
    "        #print(\"Best fit individual:\")\n",
    "        #print(anytree.RenderTree(bestFitIndividual.root))\n",
    "        \n",
    "        y_pred = bestFitIndividual.Predict(x)\n",
    "        \n",
    "        assert len(y_pred) == outputCount\n",
    "        \n",
    "        accuracy = sum( y_pred == y ) / outputCount\n",
    "        \n",
    "        #remember this gp's performance\n",
    "        if testType == TestType.TEST:\n",
    "            self.testPerformance = accuracy\n",
    "        else:\n",
    "            self.trainingPerformance = accuracy\n",
    "        \n",
    "        print(f\"{testType} Accuracy: {accuracy}\")\n",
    "        \n",
    "        t = np.arange(0, outputCount)\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 22})\n",
    "        plt.plot(t, y_pred, label='Predictions') \n",
    "        plt.plot(t, y, label='Targets') \n",
    "        #plt.hist(y, label='Predictions')\n",
    "        #plt.hist(y_pred, label='Targets')\n",
    "        plt.legend()\n",
    "        plt.grid() \n",
    "        plt.title(f'{testType} Predictions vs Targets')\n",
    "        plt.ylabel('y')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylim(-1, 2)\n",
    "        plt.show()\n",
    "    \n",
    "    def __str__(self):  \n",
    "        return f\"GP best fitness = {self.bestFitness[-1]}; GP training performance = {self.trainingPerformance}; GP test performance = {self.testPerformance};\"\n",
    "    \n",
    "test_NT = {\n",
    "        Operator(funct=sum, arity=2), \n",
    "        Operator(funct=SUBTRACT, arity=2), \n",
    "        Operator(funct=MULTIPLY, arity=2), \n",
    "        Operator(funct=DIVIDE, arity=2), #division by zero always yields zero in integer arithmetic.\n",
    "        Operator(funct=np.abs, arity=1),\n",
    "        Operator(funct=IF, arity=3),\n",
    "        Operator(funct=np.sin, arity=1),\n",
    "    }\n",
    "\n",
    "#construct terminal set\n",
    "# one x for every attribute\n",
    "test_T = set([ 'x' + str(i) for i in range(x_test.shape[1])])\n",
    "test_T.update({0, 1, 1.4, 3, 18, np.pi})\n",
    "\n",
    "test_x_train = x_train[0:5]\n",
    "test_y_train = y_train[0:5]\n",
    "test_x_test = x_test[0:5]\n",
    "test_y_test = y_test[0:5]\n",
    "    \n",
    "#test GP\n",
    "gp = GP(\n",
    "    populationSize=10,\n",
    "    initDepth=4,\n",
    "    NT=test_NT,\n",
    "    T=test_T,\n",
    "    xrate=0.9,\n",
    "    x_train=test_x_train,\n",
    "    y_train=test_y_train,\n",
    "    pairs_of_parents_elitism_saves=1,\n",
    "    #migration_size=10\n",
    ")\n",
    "\n",
    "gp.RunGen()\n",
    "\n",
    "gp.Test(test_x_test, test_y_test, testType=TestType.TEST)\n",
    "\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mstqOdlk5EQQ"
   },
   "source": [
    "### Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQyeF7Zs5EQQ"
   },
   "outputs": [],
   "source": [
    "gp = restore_object(\"saved_gps/\" + 'bestGPv2.pkl')\n",
    "\n",
    "print(gp.testPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Unsfef4AJ-5"
   },
   "source": [
    "### Implementation Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NT = {\n",
    "        Operator(funct=sum, arity=2), \n",
    "        Operator(funct=SUBTRACT, arity=2), \n",
    "        Operator(funct=MULTIPLY, arity=2), \n",
    "        Operator(funct=DIVIDE, arity=2), #division by zero always yields zero in integer arithmetic.\n",
    "        Operator(funct=np.abs, arity=1),\n",
    "        Operator(funct=IF, arity=3),\n",
    "        Operator(funct=np.sin, arity=1),\n",
    "    }\n",
    "\n",
    "#construct terminal set\n",
    "# one x for every attribute\n",
    "T = set([ 'x' + str(i) for i in range(x_test.shape[1])])\n",
    "T.update({0, 1, np.pi})\n",
    "\n",
    "POPULATION_SIZE = 100 #20 #40 \n",
    "GENERATIONS_PER_RUN = 100 #30 #60\n",
    "PAIRS_OF_PARENTS_SAVED_FOR_ELITISM = 1\n",
    "XRATE = 0.99\n",
    "INIT_DEPTH = 4 #7\n",
    "SOFT_CAP_NODE_MAX = 10 #24\n",
    "ISLANDS = 5\n",
    "MIGRATION_INTERVAL = 5\n",
    "MIGRATION_SIZE = 10\n",
    "ISLAND_MODEL = True\n",
    "ALGORITHM_ITERATIONS = 1\n",
    "RESTORED_MODEL = False #can only reuse model if it has same pop size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshuffle data every runtime\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "x_test, y_test = shuffle(x_test, y_test)\n",
    "\n",
    "#shrink datatset for faster training\n",
    "x_train_subset = x_train#[0:30] #[0:10] = 3 minute runtime, [0:30] = 8 minute runtime\n",
    "y_train_subset = y_train#[0:30]\n",
    "x_test_subset = x_test#[0:30]\n",
    "y_test_subset = y_test#[0:30]\n",
    "\n",
    "for i in range(ALGORITHM_ITERATIONS): \n",
    "    \n",
    "    if ISLAND_MODEL:\n",
    "\n",
    "        islands = np.empty(ISLANDS, dtype=GP)\n",
    "\n",
    "        #if using a restored model and it's the first algorithm run\n",
    "        if(RESTORED_MODEL and i == 0):\n",
    "            #assign it as first model\n",
    "            islands[0] = gp\n",
    "            #make sure not to overwrite it w/ init other islands\n",
    "            startIndex = 1\n",
    "        #if not restored model or later than first alg run\n",
    "        else:\n",
    "            #init all islands\n",
    "            startIndex = 0\n",
    "\n",
    "        #create all islands\n",
    "        for j in range(startIndex, ISLANDS):\n",
    "            islands[j] = GP(\n",
    "                populationSize=POPULATION_SIZE,\n",
    "                initDepth=INIT_DEPTH,\n",
    "                NT=NT,\n",
    "                T=T,\n",
    "                xrate=XRATE,\n",
    "                x_train=x_train_subset,\n",
    "                y_train=y_train_subset,\n",
    "                pairs_of_parents_elitism_saves=PAIRS_OF_PARENTS_SAVED_FOR_ELITISM,\n",
    "                softCapNodeMax=SOFT_CAP_NODE_MAX,\n",
    "                migration_size=MIGRATION_SIZE,\n",
    "                migration_interval=MIGRATION_INTERVAL\n",
    "            )\n",
    "        \n",
    "        #each generation\n",
    "        for k in range(GENERATIONS_PER_RUN):\n",
    "            \n",
    "            #if on migration interval\n",
    "            if k % MIGRATION_INTERVAL == 0:\n",
    "                #pass migration pop tween islands\n",
    "                for j in range(ISLANDS):\n",
    "                    #get island's migrants\n",
    "                    migrants = islands[j].GetMigrants()\n",
    "                    #if didn't just get immigrants from last island\n",
    "                    if j != ISLANDS-1:\n",
    "                        #pass migrants to next island\n",
    "                        islands[j+1].RecvMigrants(migrants)\n",
    "                    #if just got immigrants from last island\n",
    "                    else: \n",
    "                        #pass migrants to 1st island\n",
    "                        islands[0].RecvMigrants(migrants)\n",
    "            \n",
    "            #run every island for a gen\n",
    "            for j in range(ISLANDS):\n",
    "                \n",
    "                islands[j].RunGen()\n",
    "        \n",
    "        #every island \n",
    "        for j in range(ISLANDS):\n",
    "            \n",
    "            islandGP = islands[j]\n",
    "            \n",
    "            #if 1st island of 1st iteration, or curr gp performs better than prev best\n",
    "            if( \n",
    "               (i == 0 and j == 0) or \n",
    "               islandGP.bestFitness[-1] < bestIslandFitness\n",
    "            ):\n",
    "                #make it the best\n",
    "                bestIslandFitness = islandGP.bestFitness[-1]\n",
    "                bestIsland = islandGP\n",
    "        \n",
    "        gp = bestIsland\n",
    "        \n",
    "    else:\n",
    "        #if not using a restored model or a later alg iteration\n",
    "        if(not RESTORED_MODEL or i > 0):\n",
    "            gp = GP(\n",
    "                populationSize=POPULATION_SIZE,\n",
    "                initDepth=INIT_DEPTH,\n",
    "                NT=NT,\n",
    "                T=T,\n",
    "                xrate=XRATE,\n",
    "                x_train=x_train,\n",
    "                y_train=y_train,\n",
    "                pairs_of_parents_elitism_saves=PAIRS_OF_PARENTS_SAVED_FOR_ELITISM,\n",
    "            )\n",
    "    \n",
    "        for _ in range(GENERATIONS_PER_RUN):\n",
    "        \n",
    "            gp.RunGen()\n",
    "\n",
    "    #if first GP or curr gp performs better than prev best\n",
    "    if( i == 0 or gp.bestFitness[-1] < bestGPFitness):\n",
    "        #make it the best\n",
    "        bestGPFitness = gp.bestFitness[-1]\n",
    "        bestGP = gp\n",
    "        \n",
    "print(bestGP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestGP.PlotGenerationalFitness()\n",
    "bestGP.PlotGenerationalNodeCount()\n",
    "\n",
    "#compare to whole train set\n",
    "bestGP.Test(x_train, y_train, TestType.TRAINING)\n",
    "#compare to whole test set outside of bounds\n",
    "bestGP.Test(x_test, y_test, TestType.TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(bestGP, \"saved_gps/\" + 'bestGP_79train_74test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN + GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Fully Connected NN\n",
    "\n",
    "features = x_train.shape[1]\n",
    "hidden_nodes = (1024, 512, 256, 128, 64, 32)\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "hiddenLayers = []\n",
    "\n",
    "input_layer = layers.Input(shape=features)\n",
    "model.add(input_layer)\n",
    "\n",
    "for nodeCount in hidden_nodes:\n",
    "    \n",
    "    h_layer = layers.Dense(\n",
    "        units=nodeCount,\n",
    "        activation=activations.relu,\n",
    "    )\n",
    "    model.add(h_layer)\n",
    "    hiddenLayers.append(h_layer)\n",
    "\n",
    "o_layer = layers.Dense(\n",
    "    units=1,\n",
    "    activation=activations.sigmoid, #could also use sigmoid for GP probably\n",
    ")\n",
    "model.add(o_layer)\n",
    "\n",
    "#need normalization and output layers\n",
    "\n",
    "#specify optimization\n",
    "model.compile(optimizer=optimizers.Adam(), loss=losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GA\n",
    "### Individual Class\n",
    "- Uses global model from previous cell for fitness evaluation and value prediction\n",
    "- Otherwise, GA couldn't be unpickled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Individual():\n",
    "    def __init__(\n",
    "        self, \n",
    "        x_train, \n",
    "        y_train, \n",
    "        batch_size, \n",
    "        #model, \n",
    "        mutationChance, \n",
    "        mutationStdDev, \n",
    "        genes = None\n",
    "    ) -> None:\n",
    "        #var init\n",
    "        self.mutationStdDev = mutationStdDev\n",
    "        #self.model = model\n",
    "        self.mutationChance = mutationChance\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        #randly init genes using curr model weight shapes\n",
    "        currWeights = model.get_weights()\n",
    "        \n",
    "        if genes == None:\n",
    "            #randomly generate genes from -1 to 1\n",
    "            self.genes = [ 2 * np.random.random_sample(currWeights[i].shape) - 1 for i in range(len(currWeights)) ] \n",
    "        else:\n",
    "            self.genes = genes\n",
    "        \n",
    "        assert len(x_train) == len(y_train)\n",
    "        \n",
    "        #update model weights using genes\n",
    "        #self.UpdateWeights(self.genes)\n",
    "        \n",
    "        #fitness eval \n",
    "        self.EvaluateFitness(x_train, y_train)\n",
    "       \n",
    "    def UpdateWeights(self, newWeights):\n",
    "        #self.model.set_weights(newWeights)\n",
    "        model.set_weights(newWeights)\n",
    "       \n",
    "    def EvaluateFitness(self, x, y):\n",
    "        \"\"\"\n",
    "        Fitness evaluated through using RMSE (Root Mean Sqrd Error).\n",
    "        Lower fitness is better.\n",
    "        \"\"\"\n",
    "        \n",
    "        #predict the output given input\n",
    "        y_pred = self.Predict(x, self.batch_size)\n",
    "        \n",
    "        #sum up how many are wrong (more wrong, worse fitness)\n",
    "        fitness = sum( y_pred != y )\n",
    "            \n",
    "        self.fitness = fitness\n",
    "    \n",
    "    def Predict(self, x, batch_size = 1) -> list:\n",
    "        \"\"\"Predict output given inputs using the model.\n",
    "\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            list: _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        #make sure model weights are properly set:\n",
    "        self.UpdateWeights(self.genes)\n",
    "        \n",
    "        #y_pred = self.model.predict(x, batch_size=batch_size, verbose=0).flatten()\n",
    "        y_pred = model.predict(x, batch_size=batch_size, verbose=0).flatten()\n",
    "        \n",
    "        #need to round to nearest whole number (should be 0 or 1)\n",
    "        y_pred = np.round(y_pred)\n",
    "        \n",
    "        #if( max(y_pred) not in [0,1] or min(y_pred) not in [0,1] ):\n",
    "        #    raise ValueError\n",
    "        \n",
    "        return y_pred\n",
    "       \n",
    "    def MaybeMutate(self) -> bool:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            bool: Whether mutation occured.\n",
    "        \"\"\"\n",
    "        \n",
    "        #determine whether mutation happens\n",
    "        mutate = random.random() < self.mutationChance\n",
    "        \n",
    "        if mutate:\n",
    "            #determine new weights, changing on of them\n",
    "            newWeights = self.mutate_weights(self.genes, n_mutations=1)\n",
    "            \n",
    "            #ensure there was a change: print( DeepDiff(newWeights, self.genes) )\n",
    "            \n",
    "            #assign new weights as the genes\n",
    "            self.genes = newWeights\n",
    "            \n",
    "            #self.genes[np.random.choice(self.geneSize)] += np.random.normal(0, self.mutationStdDev)\n",
    "    \n",
    "    def get_row_and_index(self, weights, index):\n",
    "        index_const = index\n",
    "        row = 0\n",
    "        count = weights[row].size - 1\n",
    "        while count < index_const:\n",
    "            index -= weights[row].size\n",
    "            row += 1\n",
    "            count += weights[row].size\n",
    "        return row, index\n",
    "    \n",
    "    def mutate_weights(self, weights, n_mutations) -> list:\n",
    "        \"\"\"Small change happens, but not sure how much.\n",
    "\n",
    "        Args:\n",
    "            weights (_type_): _description_\n",
    "            n_mutations (_type_): number of mutations that happen\n",
    "\n",
    "        Returns:\n",
    "            list: new weights\n",
    "        \"\"\"\n",
    "        new_weights = copy.deepcopy(weights)\n",
    "        number_of_weights = 0\n",
    "        a = 0\n",
    "        b = 0\n",
    "        for i in new_weights:\n",
    "            number_of_weights += i.size\n",
    "            a = min(a, i.min())\n",
    "            b = max(b, i.max())\n",
    "        n_mutations = min(number_of_weights, n_mutations)\n",
    "\n",
    "        for i in range(n_mutations):\n",
    "            index = random.randrange(0, number_of_weights)\n",
    "            row, index = self.get_row_and_index(new_weights, index)\n",
    "            new_weight = random.uniform(a, b)\n",
    "            flat_row = new_weights[row].ravel()\n",
    "            flat_row[index] = new_weight\n",
    "    \n",
    "        return new_weights\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Individual = {self.genes}; Fitness of {self.fitness}\"  \n",
    "\n",
    "def getFitness( individual: Individual ) -> int:\n",
    "    return individual.fitness\n",
    "\n",
    "def IndividualCopy(individual) -> Individual:\n",
    "    return Individual(\n",
    "            individual.x_train,\n",
    "            individual.y_train,\n",
    "            individual.batch_size,\n",
    "            #individual.model,\n",
    "            individual.mutationChance,\n",
    "            individual.mutationStdDev,\n",
    "            genes=individual.genes\n",
    "        )\n",
    "\n",
    "indiv = Individual(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    #model,\n",
    "    mutationChance=1,\n",
    "    mutationStdDev=0.2\n",
    ")\n",
    "\n",
    "indiv.MaybeMutate()\n",
    "\n",
    "ypred = indiv.Predict(x_train)\n",
    "\n",
    "print(indiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GA():\n",
    "    \"\"\"\n",
    "    Genetic Algorithm with individuals as lists.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        populationSize: int, \n",
    "        #model: keras.Model,\n",
    "        x_train, \n",
    "        y_train, \n",
    "        batch_size,\n",
    "        pairs_of_parents_elitism_saves, \n",
    "        #island_model = False,\n",
    "        migration_interval: int = 5,\n",
    "        migration_size: int = 0,\n",
    "        xrate: float = 1\n",
    "    ):\n",
    "        self.populationSize = populationSize\n",
    "        self.localPopulationSize = populationSize - migration_size\n",
    "        self.xrate = xrate\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        #self.selectionType\n",
    "        self.currentGeneration = 0\n",
    "        self.pairs_of_parents_elitism_saves = pairs_of_parents_elitism_saves\n",
    "        self.migration_size = migration_size\n",
    "        self.migration_interval = migration_interval\n",
    "        self.batch_size=batch_size\n",
    "        self.testPerformance = 0\n",
    "        self.trainingPerformance = 0\n",
    "        \n",
    "        #create pop of 50/50 growth/full individuals\n",
    "        self.localPopulation = [\n",
    "                Individual(\n",
    "                    x_train, \n",
    "                    y_train, \n",
    "                    batch_size, \n",
    "                    #model, \n",
    "                    mutationChance = 0.8, \n",
    "                    mutationStdDev=0.2\n",
    "                ) \n",
    "                for _ in range(self.localPopulationSize)\n",
    "            ] \n",
    "        \n",
    "        #needed for migration pop creation\n",
    "        #assert self.migration_size > 3\n",
    "        \n",
    "        #can't have more immigrants than pop size\n",
    "        assert self.populationSize > migration_size\n",
    "        \n",
    "        #pop size must be even\n",
    "        assert self.populationSize % 2 == 0\n",
    "        #migration size must be even\n",
    "        assert self.migration_size % 2 == 0\n",
    "            \n",
    "        self.population = self.localPopulation #could just be empty list\n",
    "        self.recievedMigrants = []\n",
    "        self.sentMigrants = []\n",
    "        \n",
    "        #init fitness lists w/ starting pop's fitness vals\n",
    "        self.avgFitness = [] #[self.GetAvgFitness()]\n",
    "        self.bestFitness = [] #[self.GetBestFitness()]\n",
    "        self.worstFitness = [] #[self.GetWorstFitness()] \n",
    "           \n",
    "    def GetMigrants(self) -> list:\n",
    "        #if on a migration interval\n",
    "        if self.currentGeneration % self.migration_interval == 0:\n",
    "            #update migrant pop \n",
    "            self.sentMigrants = []\n",
    "            #fitness prop individuals\n",
    "            #fitnessPropIndiv1, fitnessPropIndiv2 = self.SelectParents() \n",
    "            #add best fit individual\n",
    "            self.sentMigrants.append( self.GetBestFitIndividual() )\n",
    "            #add fitness prop parents\n",
    "            #self.sentMigrants.append( fitnessPropIndiv1 )\n",
    "            #self.sentMigrants.append( fitnessPropIndiv2 )\n",
    "            #add rest of migration pop as random individuals \n",
    "            for _ in range(len(self.sentMigrants), self.migration_size):\n",
    "                self.sentMigrants.append( self.population[random.randint(1, len(self.population)-1)] ) #should randos be drawn from actual pop or local pop?\n",
    "            \n",
    "        return self.sentMigrants\n",
    "         \n",
    "    def RecvMigrants(self, migrants) -> None:\n",
    "        self.recievedMigrants = migrants\n",
    "        \n",
    "        #combine local pop + migrant pop to create island pop\n",
    "        self.population = self.localPopulation + self.recievedMigrants\n",
    "        \n",
    "    def RunGen(self) -> None:\n",
    "        #if first gen\n",
    "        if self.currentGeneration == 0:\n",
    "            #correct init pops fitness fields\n",
    "            self.avgFitness.append( self.GetAvgFitness() ) \n",
    "            self.worstFitness.append( self.GetWorstFitness() ) \n",
    "            self.bestFitness.append( self.GetBestFitness() )\n",
    "        \n",
    "        #create new pop\n",
    "        self.CreateNextGeneration()\n",
    "        \n",
    "        #store newly created pops fitness fields\n",
    "        self.avgFitness.append( self.GetAvgFitness() ) \n",
    "        self.worstFitness.append( self.GetWorstFitness() ) \n",
    "        self.bestFitness.append( self.GetBestFitness() )\n",
    "        \n",
    "        #advance gen count\n",
    "        self.currentGeneration += 1\n",
    "   \n",
    "    def CreateNextGeneration(self) ->None:\n",
    "        #ensure individuals sorted in ascending order\n",
    "        self.OrderPopulationByFitness()\n",
    "        #new pop\n",
    "        newPopulation = []\n",
    "        \n",
    "        #Save parents for elitism \n",
    "        for k in range(0, self.pairs_of_parents_elitism_saves):\n",
    "            newPopulation.append(self.population[k])\n",
    "            newPopulation.append(self.population[k+1])\n",
    "        \n",
    "        pairs_of_children = int(self.localPopulationSize/2)\n",
    "        \n",
    "        #walk thru half pop\n",
    "        for _ in range(self.pairs_of_parents_elitism_saves, pairs_of_children):\n",
    "            #select parents\n",
    "            parent1, parent2 = self.SelectParents()\n",
    "            #do crossover\n",
    "            child1, child2, xover = self.Crossover(parent1, parent2, self.xrate)\n",
    "            #if crossover happened\n",
    "            if(xover):\n",
    "                #re'eval children fitness\n",
    "                child1.EvaluateFitness(self.x_train, self.y_train)\n",
    "                child2.EvaluateFitness(self.x_train, self.y_train)\n",
    "            #add new children to next gen pop\n",
    "            newPopulation.append(child1)\n",
    "            newPopulation.append(child2)\n",
    "        \n",
    "        #walk thru every member of pop besides elites\n",
    "        for j in range(2, len(newPopulation)):\n",
    "            #possibly mutate\n",
    "            mutated = newPopulation[j].MaybeMutate()  \n",
    "            #if mutatation\n",
    "            if( mutated ):\n",
    "                #re-eval fitness\n",
    "                newPopulation[j].EvaluateFitness(self.x_train, self.y_train)\n",
    "        \n",
    "        self.localPopulation = newPopulation\n",
    "            \n",
    "        #don't needa deep copy bc newPopulation wiped out w/ leave funct\n",
    "        \n",
    "        self.population = self.localPopulation + self.recievedMigrants\n",
    "   \n",
    "    def GetBestFitIndividual(self) -> Individual:\n",
    "        return min( self.population, key=getFitness )\n",
    "    \n",
    "    def GetWorstFitIndividual(self) -> Individual:\n",
    "        return max( self.population, key=getFitness )\n",
    "   \n",
    "    def GetBestFitness(self) -> float:\n",
    "        return self.GetBestFitIndividual().fitness\n",
    "    \n",
    "    def GetWorstFitness(self) -> float:\n",
    "        return self.GetWorstFitIndividual().fitness\n",
    "    \n",
    "    def GetAvgFitness(self) -> float:\n",
    "        fitnessSum = 0\n",
    "        for i in range(0, len(self.population)):\n",
    "            #take the fitness sum\n",
    "            fitnessSum +=  self.population[i].fitness\n",
    "        \n",
    "        return fitnessSum / self.populationSize\n",
    "    \n",
    "    def Crossover(self, parent1: Individual, parent2: Individual, xrate: float = 1) -> tuple:\n",
    "        \"\"\"Swaps subtree parents at their xpoints. \n",
    "        Xpoints gauss centered around last leaf.\n",
    "        Never chooses the root node to do crossover with.\n",
    "\n",
    "        Args:\n",
    "            parent1 (Individual): _description_\n",
    "            parent2 (Individual): _description_\n",
    "\n",
    "        Returns:\n",
    "            tuple: child1, child2, whether xover happened\n",
    "        \"\"\"\n",
    "        \n",
    "        #clone children from parents\n",
    "        child1 = IndividualCopy(parent1) #copy() \n",
    "        child2 = IndividualCopy(parent2) #copy() \n",
    "        \n",
    "        #roll on whether to do crossover\n",
    "        randProb = np.random.random()\n",
    "        xover = randProb <= xrate\n",
    "        if( xover ):\n",
    "        \n",
    "            #pick crossover point\n",
    "            xpoint = random.randint(1, len(parent1.genes)-2)\n",
    "            \n",
    "            #swap parent genes at xpoint\n",
    "            child1.genes = parent1.genes[:xpoint] + parent2.genes[xpoint:]\n",
    "            child2.genes = parent2.genes[:xpoint] + parent1.genes[xpoint:]\n",
    "\n",
    "        return child1, child2, xover\n",
    "    \n",
    "    def SelectParents(self) -> tuple:\n",
    "        xIndexRange, prob = self.SetupHalfNormIntDistr(self.populationSize, stdDev=self.populationSize/3)\n",
    "    \n",
    "        #if overloaded to display distr graph\n",
    "        if(False):\n",
    "            #take randos using the calc'd prob and index range\n",
    "            nums = np.random.choice(xIndexRange, size = 1000000, p = prob)\n",
    "            #display distr histogram\n",
    "            plt.rcParams.update({'font.size': 22})\n",
    "            plt.hist(nums, bins = self.populationSize)\n",
    "            plt.title(\"likelihood of each parent index being chosen\")\n",
    "            plt.ylabel(\"likelihood of being chosen\")\n",
    "            plt.xlabel(\"parent index\")\n",
    "            plt.show()\n",
    "\n",
    "        #get parent indices\n",
    "        parent1Index, parent2Index = np.random.choice(xIndexRange, size = 2, p = prob)\n",
    "        #parent1Index, parent2Index = parentIndices[0], parentIndices[1]\n",
    "        \n",
    "        #make sure indices within array range\n",
    "        if parent1Index >= self.populationSize or parent2Index >= self.populationSize:\n",
    "            raise ValueError\n",
    "        \n",
    "        #debug: print(f\"p1Index {parent1Index}, p2Index {parent2Index}, pop length {len(self.population)}, popsize {self.populationSize}\")\n",
    "        \n",
    "        if len(self.population) != self.populationSize:\n",
    "            raise IndexError\n",
    "    \n",
    "        return self.population[int(parent1Index)], self.population[int(parent2Index)]\n",
    "    \n",
    "    def SetupHalfNormIntDistr(self, pop_size: int, stdDev: int) -> tuple:\n",
    "        \"\"\"\n",
    "        The half normal integer distribution parent indices are drawn from.\n",
    "\n",
    "        Returns:\n",
    "            tuple: index range and probability funct\n",
    "        \"\"\"\n",
    "        #take interval 1-100\n",
    "        x = np.arange(1, pop_size+1) #bc upper bound is exclusive\n",
    "        #store every number's +/-0.5\n",
    "        xU, xL = x + 0.5, x - 0.5 \n",
    "        #determine probability\n",
    "        prob = ss.halfnorm.cdf(xU, scale = stdDev) - ss.halfnorm.cdf(xL, scale = stdDev) #scale represents inner quartiles\n",
    "        prob = prob / prob.sum() # normalize the probabilities so their sum is 1\n",
    "        #decr by 1 to find the index\n",
    "        xIndexRange = x - 1\n",
    "    \n",
    "        return xIndexRange, prob\n",
    "    \n",
    "    def OrderPopulationByFitness(self):\n",
    "        #sort in descending order\n",
    "        self.population.sort(key=getFitness)\n",
    "    \n",
    "    def PlotGenerationalFitness(self):\n",
    "        t = np.arange(0, self.currentGeneration+1)\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 22})\n",
    "        plt.title('Generational Fitness Data')\n",
    "        plt.plot(t, self.worstFitness, label='Worst Fitness') \n",
    "        plt.plot(t, self.avgFitness, label='Average Fitness') \n",
    "        plt.plot(t, self.bestFitness, label='Best Fitness') \n",
    "        plt.grid() \n",
    "        plt.legend()\n",
    "        plt.ylabel('Fitness')\n",
    "        plt.xlabel('Generation')\n",
    "        \n",
    "        #init worst worst fit\n",
    "        worstWorstFitness = max(self.worstFitness)\n",
    "        \n",
    "        fitnessIndex = 0\n",
    "        \n",
    "        for fitnessData in (self.worstFitness, self.avgFitness, self.bestFitness):\n",
    "            yAnnotatePosition = worstWorstFitness - worstWorstFitness * fitnessIndex / 12\n",
    "            \n",
    "            fitnessIndex += 1\n",
    "            \n",
    "            plt.annotate('%0.7f' % min(fitnessData), xy=(1, yAnnotatePosition), xytext=(8, 0), \n",
    "                        xycoords=('axes fraction', 'data'), textcoords='offset points')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def GetBestAccuracy(self, x, y) -> float:\n",
    "        bestFitIndividual = self.GetBestFitIndividual()\n",
    "        \n",
    "        y_pred = bestFitIndividual.Predict(x)\n",
    "        \n",
    "        accuracy = sum( y_pred == y ) / len(y)\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def Test(self, x, y, testType: TestType):\n",
    "        \n",
    "        inputCount = len(x)\n",
    "        \n",
    "        outputCount = len(y)\n",
    "        \n",
    "        assert inputCount == outputCount\n",
    "            \n",
    "        bestFitIndividual = self.GetBestFitIndividual()\n",
    "        \n",
    "        #print(\"Best fit individual:\")\n",
    "        #print(anytree.RenderTree(bestFitIndividual.root))\n",
    "        \n",
    "        y_pred = bestFitIndividual.Predict(x)\n",
    "        \n",
    "        assert len(y_pred) == outputCount\n",
    "        \n",
    "        accuracy = sum( y_pred == y ) / outputCount\n",
    "        \n",
    "        #remember this gp's performance\n",
    "        if testType == TestType.TEST:\n",
    "            self.testPerformance = accuracy\n",
    "        else:\n",
    "            self.trainingPerformance = accuracy\n",
    "        \n",
    "        print(f\"{testType} Accuracy: {accuracy}\")\n",
    "        \n",
    "        t = np.arange(0, outputCount)\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 22})\n",
    "        plt.plot(t, y_pred, label='Predictions') \n",
    "        plt.plot(t, y, label='Targets') \n",
    "        plt.legend()\n",
    "        plt.grid() \n",
    "        plt.title(f'{testType} Predictions vs Targets')\n",
    "        plt.ylabel('y')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylim(-1, 2)\n",
    "        plt.show()\n",
    "    \n",
    "    def __str__(self):  \n",
    "        return f\"GP best fitness = {self.bestFitness[-1]}; GP training performance = {self.trainingPerformance}; GP test performance = {self.testPerformance};\"\n",
    "    \n",
    "#test GA\n",
    "ga = GA(\n",
    "    populationSize=30,\n",
    "    #model=model,\n",
    "    batch_size=16,\n",
    "    xrate=0.9,\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    pairs_of_parents_elitism_saves=1,\n",
    "    #migration_size=10\n",
    ")\n",
    "\n",
    "ga.RunGen()\n",
    "\n",
    "ga.PlotGenerationalFitness()\n",
    "\n",
    "print(ga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = restore_object(\"saved_gas/\" + \"bestGA_72train_58test.pkl\") \n",
    "\n",
    "print(ga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 20 #(60, 60) crashed w/ OOM\n",
    "GENERATIONS_PER_RUN = 20  \n",
    "PAIRS_OF_PARENTS_SAVED_FOR_ELITISM = 1\n",
    "XRATE = 0.95\n",
    "ISLANDS = 5\n",
    "MIGRATION_INTERVAL = 5\n",
    "MIGRATION_SIZE = 4\n",
    "ISLAND_MODEL = True\n",
    "ALGORITHM_ITERATIONS = 1\n",
    "BATCH_SIZE = 16\n",
    "RESTORED_MODEL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ISLANDS >= 2\n",
    "\n",
    "#reshuffle data every runtime\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "x_test, y_test = shuffle(x_test, y_test)\n",
    "\n",
    "for i in range(ALGORITHM_ITERATIONS): \n",
    "    \n",
    "    if ISLAND_MODEL:\n",
    "\n",
    "        islands = np.empty(ISLANDS, dtype=GA)\n",
    "        \n",
    "        #if using a restored model and it's the first algorithm run\n",
    "        if(RESTORED_MODEL and i == 0):\n",
    "            #assign it as first model\n",
    "            islands[0] = ga\n",
    "            #make sure not to overwrite it w/ init other islands\n",
    "            startIndex = 1\n",
    "        #if not restored model or later than first alg run\n",
    "        else:\n",
    "            #init all islands\n",
    "            startIndex = 0\n",
    "        \n",
    "        #create all islands\n",
    "        for j in range(startIndex, ISLANDS):\n",
    "            islands[j] = GA(\n",
    "                populationSize=POPULATION_SIZE,\n",
    "                #model=model,\n",
    "                xrate=XRATE,\n",
    "                x_train=x_train,\n",
    "                y_train=y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                pairs_of_parents_elitism_saves=PAIRS_OF_PARENTS_SAVED_FOR_ELITISM,\n",
    "                migration_size=MIGRATION_SIZE,\n",
    "                migration_interval=MIGRATION_INTERVAL\n",
    "            )\n",
    "            \n",
    "         #each generation\n",
    "        for k in range(GENERATIONS_PER_RUN):\n",
    "            \n",
    "            #if on migration interval\n",
    "            if k % MIGRATION_INTERVAL == 0:\n",
    "                #pass migration pop tween islands\n",
    "                for j in range(ISLANDS):\n",
    "                    #get island's migrants\n",
    "                    migrants = islands[j].GetMigrants()\n",
    "                    #if didn't just get immigrants from last island\n",
    "                    if j != ISLANDS-1:\n",
    "                        #pass migrants to next island\n",
    "                        islands[j+1].RecvMigrants(migrants)\n",
    "                    #if just got immigrants from last island\n",
    "                    else: \n",
    "                        #pass migrants to 1st island\n",
    "                        islands[0].RecvMigrants(migrants)\n",
    "            \n",
    "            #run every island for a gen\n",
    "            for j in range(ISLANDS):\n",
    "                \n",
    "                islands[j].RunGen()\n",
    "                \n",
    "        #every island \n",
    "        for j in range(ISLANDS):\n",
    "            \n",
    "            islandGA = islands[j]\n",
    "            \n",
    "            islandGAbestFitness = islandGA.GetBestFitness()\n",
    "            \n",
    "            print(f\"Island GA fitness = {islandGAbestFitness}\")\n",
    "            \n",
    "            #if 1st island of 1st iteration, or curr gp performs better than prev best\n",
    "            if( \n",
    "               (i == 0 and j == 0) or \n",
    "               islandGAbestFitness < bestIslandFitness\n",
    "            ):\n",
    "                #make it the best\n",
    "                bestIslandFitness = islandGAbestFitness\n",
    "                bestIsland = islandGA\n",
    "        \n",
    "        ga = bestIsland\n",
    "        \n",
    "    else:\n",
    "        #if not using a restored model or a later alg iteration\n",
    "        if(not RESTORED_MODEL or i > 0):\n",
    "            #create a new ga\n",
    "            ga = GA(\n",
    "                populationSize=POPULATION_SIZE,\n",
    "                #model=model,\n",
    "                xrate=XRATE,\n",
    "                x_train=x_train,\n",
    "                y_train=y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                pairs_of_parents_elitism_saves=PAIRS_OF_PARENTS_SAVED_FOR_ELITISM,\n",
    "            )\n",
    "        \n",
    "        for _ in range(GENERATIONS_PER_RUN):\n",
    "        \n",
    "            ga.RunGen()\n",
    "\n",
    "    gaBestFitness = ga.GetBestFitness()\n",
    "\n",
    "    #if first GP or curr gp performs better than prev best\n",
    "    if( i == 0 or gaBestFitness < bestGAFitness):\n",
    "        #make it the best\n",
    "        bestGAFitness = gaBestFitness\n",
    "        bestGA = ga\n",
    "    \n",
    "    print(f\"Best GAs fitness = {gaBestFitness}\")\n",
    "            \n",
    "print(bestGA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA Plotting and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestGA.PlotGenerationalFitness()\n",
    "\n",
    "#compare to whole train set\n",
    "bestGA.Test(x_train, y_train, TestType.TRAINING)\n",
    "#compare to whole test set outside of bounds\n",
    "bestGA.Test(x_test, y_test, TestType.TEST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pass weights of best GA's best fit individual to the model\n",
    "model.set_weights( bestGA.GetBestFitIndividual().genes )\n",
    "\n",
    "#test accuracy\n",
    "y_train_pred = model.predict(x_train)[:, 0] #cutoff last dim bc useless\n",
    "truePreds = np.sum(y_train == y_train_pred)\n",
    "test_acc = truePreds / y_train.shape[0]\n",
    "\n",
    "print(f'training accuracy: {test_acc * 100}%')\n",
    "\n",
    "#test accuracy\n",
    "y_test_pred = model.predict(x_test)[:, 0] #cutoff last dim bc useless\n",
    "truePreds = np.sum(y_test == y_test_pred)\n",
    "test_acc = truePreds / y_test.shape[0]\n",
    "\n",
    "print(f'test accuracy: {test_acc * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(bestGA, \"saved_gas/\" + \"bestGA_69train_68test.pkl\")\n",
    "\n",
    "print(bestGA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not as useful?\n",
    "\n",
    "#pass weights of best GA's best fit individual to the model\n",
    "model.set_weights( bestGA.GetBestFitIndividual().genes )\n",
    "\n",
    "model.save(\"saved_models/fc1_72train_64test_model\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"saved_models/fc1_72train_64test_model\")\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('EvoComp': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe32189b82d98f8d4c6c56307210a678aeb8b7128cbceacf7b4eb9894a56bcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
