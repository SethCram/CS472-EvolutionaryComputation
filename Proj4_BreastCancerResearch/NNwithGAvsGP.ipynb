{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Seth Cram\n",
    "Class: Evolutionary Computation - CS472/CS572\n",
    "\n",
    "Project 4\n",
    "\n",
    "Due Date: Dec 9, 2022\n",
    "\n",
    "Instructions:\n",
    "\n",
    "You should read the page and familiarize yourself with the way the data\n",
    "is formatted. Note that not all the data should be used when training your classifiers, you should select part of the data to be used to train your neural network/GP, part of the data should be reserved as a validation set.\n",
    "\n",
    "Submission information:\n",
    "\n",
    "You should construct a document where you describe your dataset, and how you had to modify or clean the dataset. You should describe the goal of the classification, why it is important, and what makes classifying the data challenging. Try to describe the search space, but note that in real world datasets, it isn't always obvious what range of values exist.\n",
    "\n",
    "Describe your algorithms. Describe all methods you used to classify the data, and descriptions of any diversity techniques you use.\n",
    "\n",
    "Plot and describe your results and any conclusions you can make from the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Cells\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules imported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "#GP imports\n",
    "import copy\n",
    "from enum import Enum\n",
    "import scipy.stats as ss\n",
    "import anytree\n",
    "from functools import reduce\n",
    "import operator as OPER\n",
    "import sklearn\n",
    "import pickle\n",
    "#NN+GA imports \n",
    "import keras \n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import activations\n",
    "from keras import losses\n",
    "from keras import applications\n",
    "import random\n",
    "from deepdiff import DeepDiff\n",
    "\n",
    "print(\"modules imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  air_time1  disp_index1  gmrt_in_air1  gmrt_on_paper1  \\\n",
      "0      id_1       5160     0.000013    120.804174       86.853334   \n",
      "1      id_2      51980     0.000016    115.318238       83.448681   \n",
      "2      id_3       2600     0.000010    229.933997      172.761858   \n",
      "3      id_4       2130     0.000010    369.403342      183.193104   \n",
      "4      id_5       2310     0.000007    257.997131      111.275889   \n",
      "..      ...        ...          ...           ...             ...   \n",
      "169  id_170       2930     0.000010    241.736477      176.115957   \n",
      "170  id_171       2140     0.000009    274.728964      234.495802   \n",
      "171  id_172       3830     0.000008    151.536989      171.104693   \n",
      "172  id_173       1760     0.000008    289.518195      196.411138   \n",
      "173  id_174       2875     0.000008    235.769350      178.208024   \n",
      "\n",
      "     max_x_extension1  max_y_extension1  mean_acc_in_air1  mean_acc_on_paper1  \\\n",
      "0                 957              6601          0.361800            0.217459   \n",
      "1                1694              6998          0.272513            0.144880   \n",
      "2                2333              5802          0.387020            0.181342   \n",
      "3                1756              8159          0.556879            0.164502   \n",
      "4                 987              4732          0.266077            0.145104   \n",
      "..                ...               ...               ...                 ...   \n",
      "169              1839              6439          0.253347            0.174663   \n",
      "170              2053              8487          0.225537            0.174920   \n",
      "171              1287              7352          0.165480            0.161058   \n",
      "172              1674              6946          0.518937            0.202613   \n",
      "173              1838              6560          0.567311            0.147818   \n",
      "\n",
      "     mean_gmrt1  ...  mean_jerk_in_air25  mean_jerk_on_paper25  \\\n",
      "0    103.828754  ...            0.141434              0.024471   \n",
      "1     99.383459  ...            0.049663              0.018368   \n",
      "2    201.347928  ...            0.178194              0.017174   \n",
      "3    276.298223  ...            0.113905              0.019860   \n",
      "4    184.636510  ...            0.121782              0.020872   \n",
      "..          ...  ...                 ...                   ...   \n",
      "169  208.926217  ...            0.119152              0.020909   \n",
      "170  254.612383  ...            0.174495              0.017640   \n",
      "171  161.320841  ...            0.114472              0.017194   \n",
      "172  242.964666  ...            0.114472              0.017194   \n",
      "173  206.988687  ...            0.114472              0.017194   \n",
      "\n",
      "     mean_speed_in_air25  mean_speed_on_paper25  num_of_pendown25  \\\n",
      "0               5.596487               3.184589                71   \n",
      "1               1.665973               0.950249               129   \n",
      "2               4.000781               2.392521                74   \n",
      "3               4.206746               1.613522               123   \n",
      "4               3.319036               1.680629                92   \n",
      "..                   ...                    ...               ...   \n",
      "169             4.508709               2.233198                96   \n",
      "170             4.685573               2.806888                84   \n",
      "171             3.493815               2.510601                88   \n",
      "172             3.493815               2.510601                88   \n",
      "173             3.493815               2.510601                88   \n",
      "\n",
      "     paper_time25  pressure_mean25  pressure_var25  total_time25  class  \n",
      "0           40120      1749.278166     296102.7676        144605      P  \n",
      "1          126700      1504.768272     278744.2850        298640      P  \n",
      "2           45480      1431.443492     144411.7055         79025      P  \n",
      "3           67945      1465.843329     230184.7154        181220      P  \n",
      "4           37285      1841.702561     158290.0255         72575      P  \n",
      "..            ...              ...             ...           ...    ...  \n",
      "169         44545      1798.923336     247448.3108         80335      H  \n",
      "170         37560      1725.619941     160664.6464        345835      H  \n",
      "171         51675      1915.573488     128727.1241         83445      H  \n",
      "172         51675      1915.573488     128727.1241         83445      H  \n",
      "173         51675      1915.573488     128727.1241         83445      H  \n",
      "\n",
      "[174 rows x 452 columns]\n",
      "Data shape: x_train: (121, 450) x_test: (53, 450)\n",
      "Data shape: y_train: (121,) y_test: (53,)\n"
     ]
    }
   ],
   "source": [
    "## load the alzheimers dataset\n",
    "def load_data(test_split = 0.3):\n",
    "    \n",
    "    ## (1) Data preparation\n",
    "    df=pd.read_csv('AlzData.csv', sep = ',')\n",
    "    print(df)\n",
    "    \n",
    "    # rm ids, rm targets\n",
    "    transposedDataFrameVals = df.values.T[1:-1].astype('float32')\n",
    "    #walk thru features\n",
    "    for i, row in enumerate(transposedDataFrameVals):\n",
    "        #normalize data [0,1]\n",
    "        transposedDataFrameVals[i] = row / max(row)\n",
    "    \n",
    "    #assign normalized data\n",
    "    X = transposedDataFrameVals.T\n",
    "    \n",
    "    #assign targets\n",
    "    targets = df.values.T[-1]\n",
    "    #conv to binary target\n",
    "    Y = np.array( [1 if target == 'P' else 0 for target in targets] )\n",
    "\n",
    "    # data split of 70 training and 30 test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_split)\n",
    "        \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_data()\n",
    "\n",
    "print('Data shape:', 'x_train:', x_train.shape, 'x_test:', x_test.shape)\n",
    "print('Data shape:', 'y_train:', y_train.shape, 'y_test:', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enum Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestType(Enum):\n",
    "    TRAINING = 0\n",
    "    VALIDATION = 1\n",
    "    TEST = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IF(ops):\n",
    "    conditional, trueRslt, falseRslt = ops[0], ops[1], ops[2]\n",
    "    \n",
    "    #print(f\"if({conditional}) then {trueRslt} else {falseRslt}\")\n",
    "    \n",
    "    if conditional:\n",
    "        return trueRslt\n",
    "    else:\n",
    "        return falseRslt\n",
    " \n",
    "def SUBTRACT(ops):\n",
    "    #print(f\"{ops[0]} - {ops[1]}\")\n",
    "    \n",
    "    return reduce(OPER.sub, ops)\n",
    "\n",
    "def MULTIPLY(ops):\n",
    "    #print(f\"{ops[0]} * {ops[1]}\")\n",
    "    \n",
    "    return reduce(OPER.mul, ops)\n",
    "    \n",
    "def DIVIDE(ops):\n",
    "    \"\"\"Protected divison\n",
    "\n",
    "    Args:\n",
    "        ops (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(f\"{ops[0]} / {ops[1]}\")\n",
    "    \n",
    "    if( ops[1] == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return ops[0] / ops[1]\n",
    "    \n",
    "class Operator():\n",
    "    def __init__(self, funct, arity) -> None:\n",
    "        self.funct = funct\n",
    "        self.arity = arity\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.funct}, arity {self.arity}\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.funct}, arity {self.arity}\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enum Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitType(Enum):\n",
    "    GROWTH = 0\n",
    "    FULL = 1\n",
    "    \n",
    "class NodeType(Enum):\n",
    "    TERMINAL = 0\n",
    "    NONTERMINAL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNUSED\n",
    "\n",
    "def softmax(z):\n",
    "    ''' softmax function for the output layer.\n",
    "        The softmax function should be able to work if batch size is greater than 1.\n",
    "\n",
    "        parameters:\n",
    "            z: input numpy array. m_batch * 10\n",
    "        \n",
    "        return: m_batch * 10     \n",
    "    '''\n",
    "    ## add your code here\n",
    "    \n",
    "    #method 1\n",
    "    \n",
    "    #axis = 0 collapses the rows to replace a val in each 1\n",
    "    #axis = 1 collapses the cols to replace a val in each 1\n",
    "    #with keepdims set, \n",
    "    # the max for every row is used in every col\n",
    "    #  the sum for every row is used in every col\n",
    "    \n",
    "    #account for over and underflow thru bounding data (preproccing) \n",
    "    z = z - np.max(z, axis=1, keepdims=True)\n",
    "    #apply softmax funct\n",
    "    y = np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "    \n",
    "    return y\n",
    "\n",
    "# test the softmax function\n",
    "z = np.array([[1, 2, 3], [4, 2, 4]])\n",
    "print(z.shape)\n",
    "s = softmax(z)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InitType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mIndividual\u001b[39;00m():\n\u001b[0;32m      2\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, initDepth: \u001b[39mint\u001b[39m, initType: InitType, NT: \u001b[39mset\u001b[39m, T: \u001b[39mset\u001b[39m, x, y, softCapNodeMax) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m         \u001b[39m#var init\u001b[39;00m\n\u001b[0;32m      4\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitType \u001b[39m=\u001b[39m initType\n",
      "Cell \u001b[1;32mIn [21], line 2\u001b[0m, in \u001b[0;36mIndividual\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mIndividual\u001b[39;00m():\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, initDepth: \u001b[39mint\u001b[39m, initType: InitType, NT: \u001b[39mset\u001b[39m, T: \u001b[39mset\u001b[39m, x, y, softCapNodeMax) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m         \u001b[39m#var init\u001b[39;00m\n\u001b[0;32m      4\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitType \u001b[39m=\u001b[39m initType\n\u001b[0;32m      5\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitDepth \u001b[39m=\u001b[39m initDepth\n",
      "\u001b[1;31mNameError\u001b[0m: name 'InitType' is not defined"
     ]
    }
   ],
   "source": [
    "class Individual():\n",
    "    def __init__(self, initDepth: int, initType: InitType, NT: set, T: set, x, y, softCapNodeMax) -> None:\n",
    "        #var init\n",
    "        self.initType = initType\n",
    "        self.initDepth = initDepth\n",
    "        self.T = T\n",
    "        self.NT = NT\n",
    "        self.softCapNodeMax = softCapNodeMax\n",
    "        \n",
    "        assert len(x) == len(y)\n",
    "        \n",
    "        #funct init\n",
    "        \n",
    "        #initialize individual as tree\n",
    "        self.nodeIndex = 0\n",
    "        self.root = self.CreateNodeNT(self.nodeIndex, parent=None)\n",
    "        self.CreateTreeRecursively(self.root)\n",
    "        #print(anytree.RenderTree(self.root))\n",
    "        \n",
    "        assert self.nodeIndex == self.GetNodeCount() - 1\n",
    "        #print(f\"self node count = {self.nodeCount}, get node count = {self.GetNodeCount()}\")\n",
    "        \n",
    "        #fitness eval of tree\n",
    "        self.EvaluateFitness(x, y)\n",
    "       \n",
    "    def EvaluateFitness(self, x, y, applyParsimonyPressure = True):\n",
    "        \"\"\"\n",
    "        Fitness evaluated through using RMSE (Root Mean Sqrd Error).\n",
    "        Applies parsimony pressure by default.\n",
    "        Lower fitness is better.\n",
    "        \"\"\"\n",
    "        \n",
    "        #predict the output given input\n",
    "        y_pred = self.Predict(x)\n",
    "        \n",
    "        #sum up how many are wrong (more wrong, worse fitness)\n",
    "        fitness = sum( y_pred != y )\n",
    "        \n",
    "        nodeCount = self.GetNodeCount()\n",
    "            \n",
    "        #if applying pressure and enough nodes to apply fitness mod\n",
    "        if applyParsimonyPressure and nodeCount > self.softCapNodeMax:\n",
    "            #incr fitness by every additional node over the max\n",
    "            fitness = fitness * (nodeCount / self.softCapNodeMax)\n",
    "            \n",
    "        self.fitness = fitness\n",
    "    \n",
    "    def Predict(self, x) -> list:\n",
    "        \"\"\"Predict output given inputs.\n",
    "        Averages outputs across each row.x_train\n",
    "        Normalization performed if average not [0, 1]\n",
    "\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            list: _description_\n",
    "        \"\"\"\n",
    "        y_tree_pred = np.empty(x.shape)\n",
    "        \n",
    "        featureCount = x.shape[0]\n",
    "        inputCount = x.shape[1]\n",
    "        \n",
    "        #walk down every col\n",
    "        for j in range(featureCount):\n",
    "            #walk across every row\n",
    "            for i in range(inputCount):\n",
    "                #NT's assigned values\n",
    "                self.EvaluateFitnessRecursively(self.root, x[j][i])\n",
    "                #store each input value's output\n",
    "                y_tree_pred[j][i] = self.root.value\n",
    "                \n",
    "        #average outputs of tree for each row into a single output\n",
    "        y_pred_prob = np.sum( y_tree_pred, axis=1) / inputCount\n",
    "            \n",
    "        #make sure each tree output is [0, 1]\n",
    "        if (max( y_tree_pred.flatten() ) > 1.1 or\n",
    "            min( y_tree_pred.flatten() < -0.1)):\n",
    "            y_pred_prob = sklearn.preprocessing.minmax_scale(y_pred_prob, feature_range=(0, 1), axis=0, copy=True)\n",
    "        \n",
    "        #round outputs to binary output\n",
    "        y_pred = np.array([round(y_pred_prob_item) for y_pred_prob_item in y_pred_prob])\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def EvaluateFitnessRecursively(self, parent: anytree.node, x: float):\n",
    "        \"\"\"NT nodes assigned values.\n",
    "\n",
    "        Args:\n",
    "            parent (anytree.node): _description_\n",
    "        \"\"\"\n",
    "        ops = []\n",
    "        #walk thru children\n",
    "        for child in parent.children:\n",
    "            #if child is NT and not evaluated\n",
    "            if (child.type == NodeType.NONTERMINAL):\n",
    "                #evaluate child (don't change input val)\n",
    "                self.EvaluateFitnessRecursively(child, x)\n",
    "            #if child val is a variable \n",
    "            if( child.value == 'x'):\n",
    "                #substitute passed in var\n",
    "                ops.append(x)\n",
    "            #regular child \n",
    "            else:\n",
    "                ops.append(child.value)\n",
    "        \n",
    "        #evaluate parent using children values\n",
    "        parent.value = float( parent.operator.funct(ops) )\n",
    "       \n",
    "    def CreateTreeRecursively(self, parent: anytree.Node) -> None:\n",
    "            #every parent is a NT\n",
    "            for _ in range(parent.operator.arity):\n",
    "                self.nodeIndex += 1\n",
    "                nodeName = self.nodeIndex\n",
    "                \n",
    "                #if creating laster layer of nodes\n",
    "                if parent.depth == self.initDepth - 2: #depth starts at 0\n",
    "                        #create T node\n",
    "                        self.CreateNodeT(nodeName, parent) \n",
    "                #if not creating last layer\n",
    "                else:\n",
    "                    if self.initType == InitType.FULL:\n",
    "                        #recursively create NT\n",
    "                        self.CreateTreeRecursively( self.CreateNodeNT(nodeName, parent) )\n",
    "                    elif self.initType == InitType.GROWTH:\n",
    "                        #roll a 50/50 on whether child is T or NT\n",
    "                        if np.random.randint(0,2) == 0:\n",
    "                            #recursively create NT\n",
    "                            self.CreateTreeRecursively( self.CreateNodeNT(nodeName, parent) )\n",
    "                        else:\n",
    "                            self.CreateNodeT(nodeName, parent)\n",
    "              \n",
    "    def CreateNodeNT(self, nodeName, parent) -> anytree.Node:\n",
    "        #create a NT child node\n",
    "        return anytree.Node(nodeName, \n",
    "            operator=random.choice(tuple(self.NT)),\n",
    "            type = NodeType.NONTERMINAL,  \n",
    "            value = 0,                                   \n",
    "            parent = parent\n",
    "        )\n",
    "    \n",
    "    def CreateNodeT(self, nodeName, parent) -> anytree.Node:\n",
    "        #create a T child node\n",
    "        return anytree.Node(nodeName, \n",
    "            value = random.choice(tuple(self.T)), \n",
    "            type = NodeType.TERMINAL, \n",
    "            parent = parent\n",
    "        )\n",
    "       \n",
    "    def GetNodeCount(self) -> int:\n",
    "        \"\"\"Calcs node count through counting the root's descendants.\n",
    "        Needs to dynamically calculate node count bc during crossover, tree size changes.\n",
    "\n",
    "        Returns:\n",
    "            int: _description_\n",
    "        \"\"\"\n",
    "        #return number of descendants and 1 to account for root\n",
    "        return len(self.root.descendants) + 1\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{anytree.RenderTree(self.root)}, fitness of {self.fitness}\"  \n",
    "\n",
    "def getFitness( individual: Individual ) -> int:\n",
    "    return individual.fitness\n",
    "\n",
    "_NT = {\n",
    "        Operator(funct=sum, arity=2), \n",
    "        Operator(funct=SUBTRACT, arity=2), \n",
    "        Operator(funct=MULTIPLY, arity=2), \n",
    "        Operator(funct=DIVIDE, arity=2), #division by zero always yields zero in integer arithmetic.\n",
    "        Operator(funct=np.abs, arity=1),\n",
    "        Operator(funct=IF, arity=3),\n",
    "        Operator(funct=np.sin, arity=1),\n",
    "    }\n",
    "\n",
    "# define optimal input value\n",
    "#x_optima = 0.96609\n",
    "#construct terminal set\n",
    "_T = {0, 1, 1.4, 3, 18, np.pi, 'x'}\n",
    "\n",
    "_y_train = y_train[0:10]\n",
    "_x_train = x_train[0:10]\n",
    "_y_test = y_test[0:10]\n",
    "_x_test = x_test[0:10]\n",
    "\n",
    "#test individual class (initDepth of 4)\n",
    "individual1 = Individual(4, InitType.FULL, _NT, _T, _x_train, _y_train, softCapNodeMax=10)\n",
    "individual2 = Individual(4, InitType.GROWTH, _NT, _T, _x_train, _y_train, softCapNodeMax=10)\n",
    "\n",
    "#Parsimony pressure testing\n",
    "print(f\"fitness: {individual1.fitness}, node count: {individual1.GetNodeCount()}\")\n",
    "print(f\"fitness: {individual2.fitness}, node count: {individual2.GetNodeCount()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP():\n",
    "    \"\"\"\n",
    "    Genetic Program with individuals as trees.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        populationSize: int, \n",
    "        initDepth: int, \n",
    "        NT: set, \n",
    "        T: set, \n",
    "        x_train, \n",
    "        y_train, \n",
    "        pairs_of_parents_elitism_saves, \n",
    "        #island_model = False,\n",
    "        migration_interval: int = 5,\n",
    "        migration_size: int = 0,\n",
    "        softCapNodeMax: int = 10, \n",
    "        xrate: float = 1\n",
    "    ):\n",
    "        self.populationSize = populationSize\n",
    "        self.localPopulationSize = populationSize - migration_size\n",
    "        self.initDepth = initDepth\n",
    "        self.NT = NT\n",
    "        self.T = T\n",
    "        self.xrate = xrate\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        #self.selectionType\n",
    "        self.currentGeneration = 0\n",
    "        self.pairs_of_parents_elitism_saves = pairs_of_parents_elitism_saves\n",
    "        self.migration_size = migration_size\n",
    "        self.migration_interval = migration_interval\n",
    "        self.testPerformance = 0\n",
    "        self.trainingPerformance = 0\n",
    "        \n",
    "        #create pop of 50/50 growth/full individuals\n",
    "        self.localPopulation = [\n",
    "                Individual(initDepth, InitType.FULL, NT, T, x_train, y_train, softCapNodeMax) \n",
    "                for _ in range(int(self.localPopulationSize/2))\n",
    "            ] + [\n",
    "                Individual(initDepth, InitType.GROWTH, NT, T, x_train, y_train, softCapNodeMax) \n",
    "                for _ in range(int(self.localPopulationSize/2))\n",
    "            ] \n",
    "        \n",
    "        #needed for migration pop creation\n",
    "        #assert self.migration_size > 3\n",
    "        \n",
    "        #can't have more immigrants than pop size\n",
    "        assert self.populationSize > migration_size\n",
    "            \n",
    "        self.population = self.localPopulation #could just be empty list\n",
    "        self.recievedMigrants = []\n",
    "        self.sentMigrants = []\n",
    "        \n",
    "        #init fitness lists w/ starting pop's fitness vals\n",
    "        self.avgFitness = [] #[self.GetAvgFitness()]\n",
    "        self.bestFitness = [] #[self.GetBestFitness()]\n",
    "        self.worstFitness = [] #[self.GetWorstFitness()] \n",
    "        self.bestFitnessNodeCount = [] #[self.GetBestFitnessNodeCount()]\n",
    "        self.worstFitnessNodeCount = [] #[self.GetWorstFitnessNodeCount()]\n",
    "           \n",
    "    def GetMigrants(self) -> list:\n",
    "        #if on a migration interval\n",
    "        if self.currentGeneration % self.migration_interval == 0:\n",
    "            #update migrant pop \n",
    "            self.sentMigrants = []\n",
    "            #fitness prop individuals\n",
    "            #fitnessPropIndiv1, fitnessPropIndiv2 = self.SelectParents() \n",
    "            #add best fit individual\n",
    "            self.sentMigrants.append( self.GetBestFitIndividual() )\n",
    "            #add fitness prop parents\n",
    "            #self.sentMigrants.append( fitnessPropIndiv1 )\n",
    "            #self.sentMigrants.append( fitnessPropIndiv2 )\n",
    "            #add rest of migration pop as random individuals \n",
    "            for _ in range(len(self.sentMigrants), self.migration_size):\n",
    "                self.sentMigrants.append( self.population[random.randint(1, len(self.population)-1)] ) #should randos be drawn from actual pop or local pop?\n",
    "            \n",
    "        return self.sentMigrants\n",
    "         \n",
    "    def RecvMigrants(self, migrants) -> None:\n",
    "        self.recievedMigrants = migrants\n",
    "        \n",
    "        #combine local pop + migrant pop to create island pop\n",
    "        self.population = self.localPopulation + self.recievedMigrants\n",
    "        \n",
    "    def RunGen(self) -> None:\n",
    "        #if first gen\n",
    "        if self.currentGeneration == 0:\n",
    "            #correct init pops fitness fields\n",
    "            self.avgFitness.append( self.GetAvgFitness() ) \n",
    "            self.worstFitness.append( self.GetWorstFitness() ) \n",
    "            self.bestFitness.append( self.GetBestFitness() )\n",
    "            self.bestFitnessNodeCount.append(self.GetBestFitnessNodeCount())\n",
    "            self.worstFitnessNodeCount.append(self.GetWorstFitnessNodeCount())\n",
    "        \n",
    "        #create new pop\n",
    "        self.CreateNextGeneration()\n",
    "        \n",
    "        #store newly created pops fitness fields\n",
    "        self.avgFitness.append( self.GetAvgFitness() ) \n",
    "        self.worstFitness.append( self.GetWorstFitness() ) \n",
    "        self.bestFitness.append( self.GetBestFitness() )\n",
    "        self.bestFitnessNodeCount.append(self.GetBestFitnessNodeCount())\n",
    "        self.worstFitnessNodeCount.append(self.GetWorstFitnessNodeCount())\n",
    "        \n",
    "        #advance gen count\n",
    "        self.currentGeneration += 1\n",
    "   \n",
    "    def CreateNextGeneration(self) ->None:\n",
    "        #ensure individuals sorted in ascending order\n",
    "        self.OrderPopulationByFitness()\n",
    "        #new pop\n",
    "        newPopulation = []\n",
    "        \n",
    "        #Save parents for elitism \n",
    "        for k in range(0, self.pairs_of_parents_elitism_saves):\n",
    "            newPopulation.append(self.population[k])\n",
    "            newPopulation.append(self.population[k+1])\n",
    "        \n",
    "        pairs_of_children = int(self.localPopulationSize/2)\n",
    "        \n",
    "        #walk thru half pop\n",
    "        for _ in range(self.pairs_of_parents_elitism_saves, pairs_of_children):\n",
    "            #select parents\n",
    "            parent1, parent2 = self.SelectParents()\n",
    "            #do crossover\n",
    "            child1, child2, xover = self.Crossover(parent1, parent2, self.xrate)\n",
    "            #if crossover happened\n",
    "            if(xover):\n",
    "                #re'eval children fitness\n",
    "                child1.EvaluateFitness(self.x_train, self.y_train)\n",
    "                child2.EvaluateFitness(self.x_train, self.y_train)\n",
    "            #add new children to next gen pop\n",
    "            newPopulation.append(child1)\n",
    "            newPopulation.append(child2)\n",
    "            \n",
    "        self.localPopulation = newPopulation\n",
    "            \n",
    "        #don't needa deep copy bc newPopulation wiped out w/ leave funct\n",
    "        \n",
    "        self.population = self.localPopulation + self.recievedMigrants\n",
    "   \n",
    "    def GetBestFitIndividual(self) -> Individual:\n",
    "        return min( self.population, key=getFitness )\n",
    "    \n",
    "    def GetWorstFitIndividual(self) -> Individual:\n",
    "        return max( self.population, key=getFitness )\n",
    "   \n",
    "    def GetBestFitnessNodeCount(self) -> int:\n",
    "        return self.GetBestFitIndividual().GetNodeCount()\n",
    "    \n",
    "    def GetWorstFitnessNodeCount(self) -> int:\n",
    "        return self.GetWorstFitIndividual().GetNodeCount()\n",
    "   \n",
    "    def GetBestFitness(self) -> float:\n",
    "        return self.GetBestFitIndividual().fitness\n",
    "    \n",
    "    def GetWorstFitness(self) -> float:\n",
    "        return self.GetWorstFitIndividual().fitness\n",
    "    \n",
    "    def GetAvgFitness(self) -> float:\n",
    "        fitnessSum = 0\n",
    "        for i in range(0, len(self.population)):\n",
    "            #take the fitness sum\n",
    "            fitnessSum +=  self.population[i].fitness\n",
    "        \n",
    "        return fitnessSum / self.populationSize\n",
    "    \n",
    "    def Crossover(self, parent1: Individual, parent2: Individual, xrate: float = 1) -> tuple:\n",
    "        \"\"\"Swaps subtree parents at their xpoints. \n",
    "        Xpoints gauss centered around last leaf.\n",
    "        Never chooses the root node to do crossover with.\n",
    "\n",
    "        Args:\n",
    "            parent1 (Individual): _description_\n",
    "            parent2 (Individual): _description_\n",
    "\n",
    "        Returns:\n",
    "            tuple: child1, child2, whether xover happened\n",
    "        \"\"\"\n",
    "        \n",
    "        #clone children from parents\n",
    "        child1 = copy.deepcopy(parent1) \n",
    "        child2 = copy.deepcopy(parent2)\n",
    "        \n",
    "        #roll on whether to do crossover\n",
    "        randProb = np.random.random()\n",
    "        xover = randProb <= xrate\n",
    "        if( xover ):\n",
    "        \n",
    "            #pick crossover subtress\n",
    "            parent1subtree, parent2subtree = self.GetCrossoverSubtrees(child1, child2)\n",
    "            \n",
    "            #swap subtree parents (don't copy)\n",
    "            parent1subtree_parent_ph = parent1subtree.parent \n",
    "            #print(anytree.RenderTree(child1.root))\n",
    "            #print(anytree.RenderTree(child2.root))\n",
    "            parent1subtree.parent = parent2subtree.parent\n",
    "            parent2subtree.parent = parent1subtree_parent_ph\n",
    "            #print(anytree.RenderTree(child1.root))\n",
    "            #print(anytree.RenderTree(child2.root))\n",
    "\n",
    "        return child1, child2, xover\n",
    "    \n",
    "    def GetCrossoverSubtrees(self, parent1, parent2) -> tuple:\n",
    "        \"\"\"Swaps subtrees at last leaf gauss random indices.\n",
    "\n",
    "        Args:\n",
    "            parent1 (_type_): _description_\n",
    "            parent2 (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            tuple: child1, child2 still connected to parent1 and parent2 (not copies)\n",
    "        \"\"\"\n",
    "        \n",
    "        #cache parent node counts\n",
    "        p1Nodes = parent1.GetNodeCount()\n",
    "        p2Nodes = parent2.GetNodeCount()\n",
    "        #find descendant node count\n",
    "        p1descendantNodes = p1Nodes - 1\n",
    "        p2descendantNodes = p2Nodes - 1\n",
    "        \n",
    "        #gen half-normal range of ints centered at 0\n",
    "        # std dev of 1/4 of descendant nodes count\n",
    "        p1xIndexRange, p1prob = self.SetupHalfNormIntDistr(p1descendantNodes, stdDev=p1descendantNodes/4)\n",
    "        p2xIndexRange, p2prob = self.SetupHalfNormIntDistr(p2descendantNodes, stdDev=p2descendantNodes/4)\n",
    "        \n",
    "        #sel parent xpoints from 1 to descendant nodes count\n",
    "        p1_xpoint = int( np.random.choice(p1xIndexRange+1, size = 1, p = p1prob) )\n",
    "        p2_xpoint = int( np.random.choice(p2xIndexRange+1, size = 1, p = p2prob) )\n",
    "        \n",
    "        #apply xpoint, starting from the end\n",
    "        # so norm distr centered around end of list (more terminals, smaller NTs)\n",
    "        parent1subtree = parent1.root.descendants[-p1_xpoint]\n",
    "        parent2subtree = parent2.root.descendants[-p2_xpoint]\n",
    "        \n",
    "        #debug: print(f\"Crossover at {parent1subtree.name} and {parent2subtree.name}\")\n",
    "        \n",
    "        assert parent1subtree != None, f\"Couldn't find a node with xpoint {-p1_xpoint-1} in tree {anytree.RenderTree(parent1.root)}\"\n",
    "        assert parent2subtree != None, f\"Couldn't find a node with xpoint {-p2_xpoint-1} in tree {anytree.RenderTree(parent2.root)}\"\n",
    "        \n",
    "        return parent1subtree, parent2subtree\n",
    "    \n",
    "    def SelectParents(self) -> tuple:\n",
    "        xIndexRange, prob = self.SetupHalfNormIntDistr(self.populationSize, stdDev=self.populationSize/3)\n",
    "    \n",
    "        #if overloaded to display distr graph\n",
    "        if(False):\n",
    "            #take randos using the calc'd prob and index range\n",
    "            nums = np.random.choice(xIndexRange, size = 1000000, p = prob)\n",
    "            #display distr histogram\n",
    "            plt.rcParams.update({'font.size': 22})\n",
    "            plt.hist(nums, bins = pop_size)\n",
    "            plt.title(\"likelihood of each parent index being chosen\")\n",
    "            plt.ylabel(\"likelihood of being chosen\")\n",
    "            plt.xlabel(\"parent index\")\n",
    "            plt.show()\n",
    "\n",
    "        #get parent indices\n",
    "        parent1Index, parent2Index = np.random.choice(xIndexRange, size = 2, p = prob)\n",
    "        #parent1Index, parent2Index = parentIndices[0], parentIndices[1]\n",
    "        \n",
    "        #make sure indices within array range\n",
    "        #assert parent1Index < self.populationSize and parent2Index < self.populationSize and type(parent1Index) == int and type(parent2Index) == int\n",
    "    \n",
    "        return self.population[int(parent1Index)], self.population[int(parent2Index)]\n",
    "    \n",
    "    def SetupHalfNormIntDistr(self, pop_size: int, stdDev: int) -> tuple:\n",
    "        \"\"\"\n",
    "        The half normal integer distribution parent indices are drawn from.\n",
    "\n",
    "        Returns:\n",
    "            tuple: index range and probability funct\n",
    "        \"\"\"\n",
    "        #take interval 1-100\n",
    "        x = np.arange(1, pop_size+1) #bc upper bound is exclusive\n",
    "        #store every number's +/-0.5\n",
    "        xU, xL = x + 0.5, x - 0.5 \n",
    "        #determine probability\n",
    "        prob = ss.halfnorm.cdf(xU, scale = stdDev) - ss.halfnorm.cdf(xL, scale = stdDev) #scale represents inner quartiles\n",
    "        prob = prob / prob.sum() # normalize the probabilities so their sum is 1\n",
    "        #decr by 1 to find the index 0-99\n",
    "        xIndexRange = x - 1\n",
    "    \n",
    "        return xIndexRange, prob\n",
    "    \n",
    "    def OrderPopulationByFitness(self):\n",
    "        #sort in descending order\n",
    "        self.population.sort(key=getFitness)\n",
    "    \n",
    "    def PlotGenerationalFitness(self):\n",
    "        t = np.arange(0, self.currentGeneration+1)\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 22})\n",
    "        plt.title('Generational Fitness Data')\n",
    "        plt.plot(t, self.worstFitness, label='Worst Fitness') \n",
    "        plt.plot(t, self.avgFitness, label='Average Fitness') \n",
    "        plt.plot(t, self.bestFitness, label='Best Fitness') \n",
    "        plt.grid() \n",
    "        plt.legend()\n",
    "        plt.ylabel('Fitness')\n",
    "        plt.xlabel('Generation')\n",
    "        \n",
    "        #init worst worst fit\n",
    "        worstWorstFitness = max(self.worstFitness)\n",
    "        \n",
    "        fitnessIndex = 0\n",
    "        \n",
    "        for fitnessData in (self.worstFitness, self.avgFitness, self.bestFitness):\n",
    "            yAnnotatePosition = worstWorstFitness - worstWorstFitness * fitnessIndex / 12\n",
    "            \n",
    "            fitnessIndex += 1\n",
    "            \n",
    "            plt.annotate('%0.7f' % min(fitnessData), xy=(1, yAnnotatePosition), xytext=(8, 0), \n",
    "                        xycoords=('axes fraction', 'data'), textcoords='offset points')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def PlotGenerationalNodeCount(self):\n",
    "        t = np.arange(0, self.currentGeneration+1)\n",
    "            \n",
    "        plt.rcParams.update({'font.size': 22})\n",
    "        plt.plot(t, self.bestFitnessNodeCount, label='Best Fitness') \n",
    "        plt.plot(t, self.worstFitnessNodeCount, label='Worst Fitness')\n",
    "        plt.grid() \n",
    "        plt.legend()\n",
    "        plt.title('Node Count per Generation')\n",
    "        plt.ylabel('Node Count')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.show()\n",
    "    \n",
    "    def Test(self, x, y, testType: TestType):\n",
    "        \n",
    "        inputCount = len(x)\n",
    "        \n",
    "        outputCount = len(y)\n",
    "        \n",
    "        assert inputCount == outputCount\n",
    "        \n",
    "        #for i in range(self.populationSize): #why re-eval fitness for new data??\n",
    "        #    self.population[i].EvaluateFitness(x, y)\n",
    "            \n",
    "        bestFitIndividual = self.GetBestFitIndividual()\n",
    "        \n",
    "        #print(\"Best fit individual:\")\n",
    "        #print(anytree.RenderTree(bestFitIndividual.root))\n",
    "        \n",
    "        y_pred = bestFitIndividual.Predict(x)\n",
    "        \n",
    "        assert len(y_pred) == outputCount\n",
    "        \n",
    "        accuracy = sum( y_pred == y ) / outputCount\n",
    "        \n",
    "        #remember this gp's performance\n",
    "        if testType == TestType.TEST:\n",
    "            self.testPerformance = accuracy\n",
    "        else:\n",
    "            self.trainingPerformance = accuracy\n",
    "        \n",
    "        print(f\"{testType} Accuracy: {accuracy}\")\n",
    "        \n",
    "        t = np.arange(0, outputCount)\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 22})\n",
    "        plt.plot(t, y_pred, label='Predictions') \n",
    "        plt.plot(t, y, label='Targets') \n",
    "        #plt.hist(y, label='Predictions')\n",
    "        #plt.hist(y_pred, label='Targets')\n",
    "        plt.legend()\n",
    "        plt.grid() \n",
    "        plt.title(f'{testType} Predictions vs Targets')\n",
    "        plt.ylabel('y')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylim(-1, 2)\n",
    "        plt.show()\n",
    "    \n",
    "    def __str__(self):  \n",
    "        return f\"GP best fitness = {self.bestFitness[-1]}; GP training performance = {self.trainingPerformance}; GP test performance = {self.testPerformance};\"\n",
    "    \n",
    "test_NT = {\n",
    "        Operator(funct=sum, arity=2), \n",
    "        Operator(funct=SUBTRACT, arity=2), \n",
    "        Operator(funct=MULTIPLY, arity=2), \n",
    "        Operator(funct=DIVIDE, arity=2), #division by zero always yields zero in integer arithmetic.\n",
    "        Operator(funct=np.abs, arity=1),\n",
    "        Operator(funct=IF, arity=3),\n",
    "        Operator(funct=np.sin, arity=1),\n",
    "    }\n",
    "\n",
    "#construct terminal set\n",
    "test_T = {'x', 1}\n",
    "\n",
    "test_x_train = x_train[0:5]\n",
    "test_y_train = y_train[0:5]\n",
    "test_x_test = x_test[0:5]\n",
    "test_y_test = y_test[0:5]\n",
    "    \n",
    "#test GP\n",
    "gp = GP(\n",
    "    populationSize=10,\n",
    "    initDepth=4,\n",
    "    NT=test_NT,\n",
    "    T=test_T,\n",
    "    xrate=0.9,\n",
    "    x_train=test_x_train,\n",
    "    y_train=test_y_train,\n",
    "    pairs_of_parents_elitism_saves=1,\n",
    "    #migration_size=10\n",
    ")\n",
    "\n",
    "gp.RunGen()\n",
    "\n",
    "gp.Test(test_x_test, test_y_test, testType=TestType.TEST)\n",
    "\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Implementation\n",
    "### Implementation Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NT = {\n",
    "        Operator(funct=sum, arity=2), \n",
    "        Operator(funct=SUBTRACT, arity=2), \n",
    "        Operator(funct=MULTIPLY, arity=2), \n",
    "        Operator(funct=DIVIDE, arity=2), #division by zero always yields zero in integer arithmetic.\n",
    "        Operator(funct=np.abs, arity=1),\n",
    "        Operator(funct=IF, arity=3),\n",
    "        Operator(funct=np.sin, arity=1),\n",
    "    }\n",
    "\n",
    "#construct terminal set\n",
    "T = {0, 1, 1.4, 3, 18, np.pi, 'x'}\n",
    "\n",
    "POPULATION_SIZE = 20 #40 \n",
    "GENERATIONS_PER_RUN = 30 #60\n",
    "PAIRS_OF_PARENTS_SAVED_FOR_ELITISM = 1\n",
    "XRATE = 0.95\n",
    "INIT_DEPTH = 4\n",
    "ISLANDS = 5\n",
    "MIGRATION_INTERVAL = 5\n",
    "MIGRATION_SIZE = 10\n",
    "ISLAND_MODEL = True\n",
    "ALGORITHM_ITERATIONS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shrink datatset for faster training\n",
    "x_train_subset = x_train[0:30] #[0:10] = 3 minute runtime, [0:30] = 8 minute runtime\n",
    "y_train_subset = y_train[0:30]\n",
    "x_test_subset = x_test[0:30]\n",
    "y_test_subset = y_test[0:30]\n",
    "\n",
    "for i in range(ALGORITHM_ITERATIONS): \n",
    "    \n",
    "    if ISLAND_MODEL:\n",
    "\n",
    "        islands = np.empty(ISLANDS, dtype=GP)\n",
    "\n",
    "        #create all islands\n",
    "        for j in range(ISLANDS):\n",
    "            islands[j] = GP(\n",
    "                populationSize=POPULATION_SIZE,\n",
    "                initDepth=INIT_DEPTH,\n",
    "                NT=NT,\n",
    "                T=T,\n",
    "                xrate=XRATE,\n",
    "                x_train=x_train_subset,\n",
    "                y_train=y_train_subset,\n",
    "                pairs_of_parents_elitism_saves=PAIRS_OF_PARENTS_SAVED_FOR_ELITISM,\n",
    "                migration_size=MIGRATION_SIZE,\n",
    "                migration_interval=MIGRATION_INTERVAL\n",
    "            )\n",
    "        \n",
    "        #each generation\n",
    "        for k in range(GENERATIONS_PER_RUN):\n",
    "            \n",
    "            #if on migration interval\n",
    "            if k % MIGRATION_INTERVAL == 0:\n",
    "                #pass migration pop tween islands\n",
    "                for j in range(ISLANDS):\n",
    "                    #get island's migrants\n",
    "                    migrants = islands[j].GetMigrants()\n",
    "                    #if didn't just get immigrants from last island\n",
    "                    if j != ISLANDS-1:\n",
    "                        #pass migrants to next island\n",
    "                        islands[j+1].RecvMigrants(migrants)\n",
    "                    #if just got immigrants from last island\n",
    "                    else: \n",
    "                        #pass migrants to 1st island\n",
    "                        islands[0].RecvMigrants(migrants)\n",
    "            \n",
    "            #run every island for a gen\n",
    "            for j in range(ISLANDS):\n",
    "                \n",
    "                islands[j].RunGen()\n",
    "        \n",
    "        #every island \n",
    "        for j in range(ISLANDS):\n",
    "            \n",
    "            islandGP = islands[j]\n",
    "            \n",
    "            #if 1st island of 1st iteration, or curr gp performs better than prev best\n",
    "            if( \n",
    "               (i == 0 and j == 0) or \n",
    "               islandGP.bestFitness[-1] < bestIslandFitness\n",
    "            ):\n",
    "                #make it the best\n",
    "                bestIslandFitness = islandGP.bestFitness[-1]\n",
    "                bestIsland = islandGP\n",
    "        \n",
    "        gp = bestIsland\n",
    "        \n",
    "    else:\n",
    "        gp = GP(\n",
    "            populationSize=POPULATION_SIZE,\n",
    "            initDepth=INIT_DEPTH,\n",
    "            NT=NT,\n",
    "            T=T,\n",
    "            xrate=XRATE,\n",
    "            x_train=x_train,\n",
    "            y_train=y_train,\n",
    "            pairs_of_parents_elitism_saves=PAIRS_OF_PARENTS_SAVED_FOR_ELITISM,\n",
    "        )\n",
    "    \n",
    "        for _ in range(GENERATIONS_PER_RUN):\n",
    "        \n",
    "            gp.RunGen()\n",
    "\n",
    "    #if first GP or curr gp performs better than prev best\n",
    "    if( i == 0 or gp.bestFitness[-1] < bestGPFitness):\n",
    "        #make it the best\n",
    "        bestGPFitness = gp.bestFitness[-1]\n",
    "        bestGP = gp\n",
    "        \n",
    "print(bestGP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestGP.PlotGenerationalFitness()\n",
    "bestGP.PlotGenerationalNodeCount()\n",
    "\n",
    "#compare to whole train set\n",
    "bestGP.Test(x_train, y_train, TestType.TRAINING)\n",
    "#compare to whole test set outside of bounds\n",
    "bestGP.Test(x_test, y_test, TestType.TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename) -> None:\n",
    "    with open(\"saved_gps/\" + filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# sample usage\n",
    "save_object(bestGP, 'bestGPv2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_object(fileName) -> GP:\n",
    "    with open(\"saved_gps/\" + fileName, 'rb') as inp:\n",
    "        gp = pickle.load(inp)\n",
    "        \n",
    "    return gp\n",
    "\n",
    "gp = restore_object('bestGPv2.pkl')\n",
    "\n",
    "print(gp.testPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN + GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                28864     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,977\n",
      "Trainable params: 30,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Fully Connected NN\n",
    "\n",
    "features = x_train.shape[1]\n",
    "hidden_nodes = (64, 32)\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "hiddenLayers = []\n",
    "\n",
    "h_layer = layers.Dense(\n",
    "    input_dim=features,\n",
    "    units=hidden_nodes[0],\n",
    "    activation=activations.relu,\n",
    ")\n",
    "hiddenLayers.append(h_layer)\n",
    "model.add(h_layer)\n",
    "\n",
    "h_layer = layers.Dense(\n",
    "    input_dim=features,\n",
    "    units=hidden_nodes[1],\n",
    "    activation=activations.relu,\n",
    ")\n",
    "hiddenLayers.append(h_layer)\n",
    "model.add(h_layer)\n",
    "\n",
    "o_layer = layers.Dense(\n",
    "    input_dim=hidden_nodes[0],\n",
    "    units=1,\n",
    "    activation=activations.sigmoid,\n",
    ")\n",
    "model.add(o_layer)\n",
    "\n",
    "#need normalization and output layers\n",
    "\n",
    "#specify optimization\n",
    "model.compile(optimizer=optimizers.Adam(), loss=losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GA\n",
    "### Individual Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "Individual = [array([[0.02359392, 0.05526688, 0.12910999, ..., 0.39518556, 0.64639279,\n",
      "        0.19544312],\n",
      "       [0.48465567, 0.51423372, 0.86199834, ..., 0.36446107, 0.35599954,\n",
      "        0.10751089],\n",
      "       [0.04648227, 0.57231963, 0.52270622, ..., 0.78046689, 0.11570828,\n",
      "        0.56026882],\n",
      "       ...,\n",
      "       [0.67592287, 0.03574601, 0.94289072, ..., 0.89246352, 0.83721056,\n",
      "        0.71379131],\n",
      "       [0.66984475, 0.81029307, 0.82563894, ..., 0.14394558, 0.08934603,\n",
      "        0.51338143],\n",
      "       [0.68990055, 0.02009332, 0.80936825, ..., 0.67519298, 0.43370576,\n",
      "        0.09780283]]), array([4.10097068e-01, 6.32712209e-01, 5.07553192e-01, 7.44481570e-01,\n",
      "       3.82284550e-01, 2.57069012e-01, 4.45369133e-01, 4.13511028e-01,\n",
      "       3.07536433e-01, 2.60534003e-01, 3.74466981e-01, 7.85109562e-01,\n",
      "       7.16656855e-01, 8.79774778e-01, 7.08164251e-01, 9.32546954e-01,\n",
      "       7.63841324e-01, 2.93330055e-01, 4.29883190e-01, 7.22770574e-01,\n",
      "       3.90905938e-01, 3.81430751e-01, 2.02246048e-01, 2.28310041e-01,\n",
      "       8.73783052e-05, 2.69257989e-01, 3.87041506e-01, 9.93567062e-01,\n",
      "       8.78780973e-01, 8.10207308e-01, 9.13621985e-01, 1.42693408e-01,\n",
      "       7.95525332e-01, 9.97595698e-02, 9.28236630e-01, 4.20585968e-01,\n",
      "       2.03658991e-01, 4.87863803e-01, 4.26996922e-01, 9.30370591e-01,\n",
      "       5.60524044e-01, 9.76121282e-01, 1.68258808e-01, 1.11627542e-01,\n",
      "       5.95386639e-01, 2.49553896e-01, 5.07442239e-02, 6.25724610e-01,\n",
      "       3.49592395e-01, 2.99063734e-01, 3.60462199e-02, 7.52731584e-01,\n",
      "       3.84138131e-02, 1.05346783e-01, 6.24688005e-01, 9.05936738e-01,\n",
      "       4.06593516e-01, 2.65208345e-02, 5.56050400e-02, 9.51866634e-01,\n",
      "       2.90239732e-01, 2.31008141e-01, 9.58421097e-01, 3.76409918e-01]), array([[0.96984425, 0.31132432, 0.42696415, ..., 0.72256979, 0.47424959,\n",
      "        0.63396914],\n",
      "       [0.68882698, 0.71007112, 0.11029507, ..., 0.59630559, 0.74635702,\n",
      "        0.54434346],\n",
      "       [0.57827532, 0.32851167, 0.98943775, ..., 0.27595454, 0.04546695,\n",
      "        0.4651615 ],\n",
      "       ...,\n",
      "       [0.84011301, 0.54495079, 0.37685191, ..., 0.22863286, 0.86227476,\n",
      "        0.67707283],\n",
      "       [0.8911639 , 0.91043715, 0.10687823, ..., 0.09530494, 0.2145022 ,\n",
      "        0.77258789],\n",
      "       [0.16512257, 0.14341871, 0.21320299, ..., 0.40640123, 0.41536051,\n",
      "        0.1515513 ]]), array([0.08636914, 0.65533015, 0.88190161, 0.29488209, 0.79929528,\n",
      "       0.91694376, 0.8658015 , 0.80772863, 0.53175285, 0.49353777,\n",
      "       0.4404595 , 0.41251494, 0.28790127, 0.10263453, 0.32253809,\n",
      "       0.25911235, 0.58093295, 0.0581866 , 0.7920835 , 0.1741345 ,\n",
      "       0.63623377, 0.31995233, 0.22384464, 0.40315456, 0.12109829,\n",
      "       0.65734595, 0.81657046, 0.78652838, 0.59302266, 0.12581616,\n",
      "       0.46840937, 0.59996358]), array([[0.73037458],\n",
      "       [0.37635962],\n",
      "       [0.55129729],\n",
      "       [0.00478582],\n",
      "       [0.61561327],\n",
      "       [0.08171044],\n",
      "       [0.06199428],\n",
      "       [0.40475353],\n",
      "       [0.5527886 ],\n",
      "       [0.10440411],\n",
      "       [0.71798832],\n",
      "       [0.26980308],\n",
      "       [0.68284198],\n",
      "       [0.26597626],\n",
      "       [0.03986744],\n",
      "       [0.64673455],\n",
      "       [0.64664747],\n",
      "       [0.20591593],\n",
      "       [0.62930431],\n",
      "       [0.30832083],\n",
      "       [0.59358416],\n",
      "       [0.57310183],\n",
      "       [0.20120706],\n",
      "       [0.27522716],\n",
      "       [0.72558081],\n",
      "       [0.43901373],\n",
      "       [0.93407279],\n",
      "       [0.61629446],\n",
      "       [0.76286868],\n",
      "       [0.38706412],\n",
      "       [0.78444101],\n",
      "       [0.36559979]]), array([0.81506607])]; Fitness of 61\n"
     ]
    }
   ],
   "source": [
    "class Individual():\n",
    "    def __init__(self, x_train, y_train, model, mutationChance, mutationStdDev, genes = None) -> None:\n",
    "        #var init\n",
    "        self.mutationStdDev = mutationStdDev\n",
    "        self.model = model\n",
    "        self.mutationChance = mutationChance\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        #randly init genes using curr model weight shapes\n",
    "        currWeights = model.get_weights()\n",
    "        \n",
    "        if genes == None:\n",
    "            self.genes = [ np.random.random_sample(currWeights[i].shape) for i in range(len(currWeights)) ] \n",
    "        else:\n",
    "            self.genes = genes\n",
    "        \n",
    "        assert len(x_train) == len(y_train)\n",
    "        \n",
    "        #update model weights using genes\n",
    "        self.UpdateWeights(self.genes)\n",
    "        \n",
    "        #fitness eval \n",
    "        self.EvaluateFitness(x_train, y_train)\n",
    "       \n",
    "    def UpdateWeights(self, newWeights):\n",
    "        self.model.set_weights(newWeights)\n",
    "       \n",
    "    def EvaluateFitness(self, x, y):\n",
    "        \"\"\"\n",
    "        Fitness evaluated through using RMSE (Root Mean Sqrd Error).\n",
    "        Lower fitness is better.\n",
    "        \"\"\"\n",
    "        \n",
    "        #predict the output given input\n",
    "        y_pred = self.Predict(x).flatten()\n",
    "        \n",
    "        #sum up how many are wrong (more wrong, worse fitness)\n",
    "        fitness = sum( y_pred != y )\n",
    "            \n",
    "        self.fitness = fitness\n",
    "    \n",
    "    def Predict(self, x) -> list:\n",
    "        \"\"\"Predict output given inputs using the model.\n",
    "\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            list: _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        y_pred = self.model.predict(x)\n",
    "        \n",
    "        return y_pred\n",
    "       \n",
    "    def MaybeMutate(self) -> bool:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            bool: Whether mutation occured.\n",
    "        \"\"\"\n",
    "        \n",
    "        #determine whether mutation happens\n",
    "        mutate = random.random() < self.mutationChance\n",
    "        \n",
    "        if mutate:\n",
    "            #determine new weights, changing on of them\n",
    "            newWeights = self.mutate_weights(self.genes, n_mutations=1)\n",
    "            \n",
    "            #ensure there was a change\n",
    "            print( DeepDiff(newWeights, self.genes) )\n",
    "            \n",
    "            #assign new weights as the genes\n",
    "            self.genes = newWeights\n",
    "            \n",
    "            #self.genes[np.random.choice(self.geneSize)] += np.random.normal(0, self.mutationStdDev)\n",
    "    \n",
    "    def get_row_and_index(self, weights, index):\n",
    "        index_const = index\n",
    "        row = 0\n",
    "        count = weights[row].size - 1\n",
    "        while count < index_const:\n",
    "            index -= weights[row].size\n",
    "            row += 1\n",
    "            count += weights[row].size\n",
    "        return row, index\n",
    "    \n",
    "    def mutate_weights(self, weights, n_mutations) -> list:\n",
    "        \"\"\"Small change happens, but not sure how much.\n",
    "\n",
    "        Args:\n",
    "            weights (_type_): _description_\n",
    "            n_mutations (_type_): number of mutations that happen\n",
    "\n",
    "        Returns:\n",
    "            list: new weights\n",
    "        \"\"\"\n",
    "        new_weights = copy.deepcopy(weights)\n",
    "        number_of_weights = 0\n",
    "        a = 0\n",
    "        b = 0\n",
    "        for i in new_weights:\n",
    "            number_of_weights += i.size\n",
    "            a = min(a, i.min())\n",
    "            b = max(b, i.max())\n",
    "        n_mutations = min(number_of_weights, n_mutations)\n",
    "\n",
    "        for i in range(n_mutations):\n",
    "            index = random.randrange(0, number_of_weights)\n",
    "            row, index = self.get_row_and_index(new_weights, index)\n",
    "            new_weight = random.uniform(a, b)\n",
    "            flat_row = new_weights[row].ravel()\n",
    "            flat_row[index] = new_weight\n",
    "    \n",
    "        return new_weights\n",
    "\n",
    "    def copy(self) -> Individual:\n",
    "        return Individual(\n",
    "                self.x_train,\n",
    "                self.y_train,\n",
    "                self.model,\n",
    "                self.mutationChance,\n",
    "                self.mutationStdDev,\n",
    "                genes=self.genes\n",
    "            )\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Individual = {self.genes}; Fitness of {self.fitness}\"  \n",
    "\n",
    "def getFitness( individual: Individual ) -> int:\n",
    "    return individual.fitness\n",
    "\n",
    "indiv = Individual(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    model,\n",
    "    mutationChance=0.1,\n",
    "    mutationStdDev=0.2\n",
    ")\n",
    "\n",
    "indiv.MaybeMutate()\n",
    "\n",
    "print(indiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 337\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[39m#test GA\u001b[39;00m\n\u001b[0;32m    327\u001b[0m ga \u001b[39m=\u001b[39m GA(\n\u001b[0;32m    328\u001b[0m     populationSize\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m,\n\u001b[0;32m    329\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[39m#migration_size=10\u001b[39;00m\n\u001b[0;32m    335\u001b[0m )\n\u001b[1;32m--> 337\u001b[0m ga\u001b[39m.\u001b[39;49mRunGen()\n\u001b[0;32m    339\u001b[0m \u001b[39mprint\u001b[39m(ga)\n",
      "Cell \u001b[1;32mIn [16], line 84\u001b[0m, in \u001b[0;36mGA.RunGen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbestFitness\u001b[39m.\u001b[39mappend( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGetBestFitness() )\n\u001b[0;32m     83\u001b[0m \u001b[39m#create new pop\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mCreateNextGeneration()\n\u001b[0;32m     86\u001b[0m \u001b[39m#store newly created pops fitness fields\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgFitness\u001b[39m.\u001b[39mappend( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGetAvgFitness() ) \n",
      "Cell \u001b[1;32mIn [16], line 110\u001b[0m, in \u001b[0;36mGA.CreateNextGeneration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39m#walk thru half pop\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpairs_of_parents_elitism_saves, pairs_of_children):\n\u001b[0;32m    109\u001b[0m     \u001b[39m#select parents\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     parent1, parent2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelectParents()\n\u001b[0;32m    111\u001b[0m     \u001b[39m#do crossover\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     child1, child2, xover \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCrossover(parent1, parent2, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxrate)\n",
      "Cell \u001b[1;32mIn [16], line 220\u001b[0m, in \u001b[0;36mGA.SelectParents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    214\u001b[0m parent1Index, parent2Index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(xIndexRange, size \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, p \u001b[39m=\u001b[39m prob)\n\u001b[0;32m    215\u001b[0m \u001b[39m#parent1Index, parent2Index = parentIndices[0], parentIndices[1]\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \n\u001b[0;32m    217\u001b[0m \u001b[39m#make sure indices within array range\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m#assert parent1Index < self.populationSize and parent2Index < self.populationSize and type(parent1Index) == int and type(parent2Index) == int\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation[\u001b[39mint\u001b[39m(parent1Index)], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpopulation[\u001b[39mint\u001b[39;49m(parent2Index)]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "class GA():\n",
    "    \"\"\"\n",
    "    Genetic Algorithm with individuals as lists.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        populationSize: int, \n",
    "        model: keras.Model,\n",
    "        x_train, \n",
    "        y_train, \n",
    "        pairs_of_parents_elitism_saves, \n",
    "        #island_model = False,\n",
    "        migration_interval: int = 5,\n",
    "        migration_size: int = 0,\n",
    "        xrate: float = 1\n",
    "    ):\n",
    "        self.populationSize = populationSize\n",
    "        self.localPopulationSize = populationSize - migration_size\n",
    "        self.xrate = xrate\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        #self.selectionType\n",
    "        self.currentGeneration = 0\n",
    "        self.pairs_of_parents_elitism_saves = pairs_of_parents_elitism_saves\n",
    "        self.migration_size = migration_size\n",
    "        self.migration_interval = migration_interval\n",
    "        self.testPerformance = 0\n",
    "        self.trainingPerformance = 0\n",
    "        \n",
    "        #create pop of 50/50 growth/full individuals\n",
    "        self.localPopulation = [\n",
    "                Individual(x_train, y_train, model, mutationChance = 0.8, mutationStdDev=0.2) \n",
    "                for _ in range(int(self.localPopulationSize/2))\n",
    "            ] \n",
    "        \n",
    "        #needed for migration pop creation\n",
    "        #assert self.migration_size > 3\n",
    "        \n",
    "        #can't have more immigrants than pop size\n",
    "        assert self.populationSize > migration_size\n",
    "            \n",
    "        self.population = self.localPopulation #could just be empty list\n",
    "        self.recievedMigrants = []\n",
    "        self.sentMigrants = []\n",
    "        \n",
    "        #init fitness lists w/ starting pop's fitness vals\n",
    "        self.avgFitness = [] #[self.GetAvgFitness()]\n",
    "        self.bestFitness = [] #[self.GetBestFitness()]\n",
    "        self.worstFitness = [] #[self.GetWorstFitness()] \n",
    "           \n",
    "    def GetMigrants(self) -> list:\n",
    "        #if on a migration interval\n",
    "        if self.currentGeneration % self.migration_interval == 0:\n",
    "            #update migrant pop \n",
    "            self.sentMigrants = []\n",
    "            #fitness prop individuals\n",
    "            #fitnessPropIndiv1, fitnessPropIndiv2 = self.SelectParents() \n",
    "            #add best fit individual\n",
    "            self.sentMigrants.append( self.GetBestFitIndividual() )\n",
    "            #add fitness prop parents\n",
    "            #self.sentMigrants.append( fitnessPropIndiv1 )\n",
    "            #self.sentMigrants.append( fitnessPropIndiv2 )\n",
    "            #add rest of migration pop as random individuals \n",
    "            for _ in range(len(self.sentMigrants), self.migration_size):\n",
    "                self.sentMigrants.append( self.population[random.randint(1, len(self.population)-1)] ) #should randos be drawn from actual pop or local pop?\n",
    "            \n",
    "        return self.sentMigrants\n",
    "         \n",
    "    def RecvMigrants(self, migrants) -> None:\n",
    "        self.recievedMigrants = migrants\n",
    "        \n",
    "        #combine local pop + migrant pop to create island pop\n",
    "        self.population = self.localPopulation + self.recievedMigrants\n",
    "        \n",
    "    def RunGen(self) -> None:\n",
    "        #if first gen\n",
    "        if self.currentGeneration == 0:\n",
    "            #correct init pops fitness fields\n",
    "            self.avgFitness.append( self.GetAvgFitness() ) \n",
    "            self.worstFitness.append( self.GetWorstFitness() ) \n",
    "            self.bestFitness.append( self.GetBestFitness() )\n",
    "        \n",
    "        #create new pop\n",
    "        self.CreateNextGeneration()\n",
    "        \n",
    "        #store newly created pops fitness fields\n",
    "        self.avgFitness.append( self.GetAvgFitness() ) \n",
    "        self.worstFitness.append( self.GetWorstFitness() ) \n",
    "        self.bestFitness.append( self.GetBestFitness() )\n",
    "        \n",
    "        #advance gen count\n",
    "        self.currentGeneration += 1\n",
    "   \n",
    "    def CreateNextGeneration(self) ->None:\n",
    "        #ensure individuals sorted in ascending order\n",
    "        self.OrderPopulationByFitness()\n",
    "        #new pop\n",
    "        newPopulation = []\n",
    "        \n",
    "        #Save parents for elitism \n",
    "        for k in range(0, self.pairs_of_parents_elitism_saves):\n",
    "            newPopulation.append(self.population[k])\n",
    "            newPopulation.append(self.population[k+1])\n",
    "        \n",
    "        pairs_of_children = int(self.localPopulationSize/2)\n",
    "        \n",
    "        #walk thru half pop\n",
    "        for _ in range(self.pairs_of_parents_elitism_saves, pairs_of_children):\n",
    "            #select parents\n",
    "            parent1, parent2 = self.SelectParents()\n",
    "            #do crossover\n",
    "            child1, child2, xover = self.Crossover(parent1, parent2, self.xrate)\n",
    "            #if crossover happened\n",
    "            if(xover):\n",
    "                #re'eval children fitness\n",
    "                child1.EvaluateFitness(self.x_train, self.y_train)\n",
    "                child2.EvaluateFitness(self.x_train, self.y_train)\n",
    "            #add new children to next gen pop\n",
    "            newPopulation.append(child1)\n",
    "            newPopulation.append(child2)\n",
    "        \n",
    "        #walk thru every member of pop besides elites\n",
    "        for j in range(2, len(newPopulation)):\n",
    "            #possibly mutate\n",
    "            mutated = newPopulation[j].MaybeMutate()  \n",
    "            #if mutatation\n",
    "            if( mutated ):\n",
    "                #re-eval fitness\n",
    "                newPopulation[j].EvaluateFitness(self.x_train, self.y_train)\n",
    "        \n",
    "        self.localPopulation = newPopulation\n",
    "            \n",
    "        #don't needa deep copy bc newPopulation wiped out w/ leave funct\n",
    "        \n",
    "        self.population = self.localPopulation + self.recievedMigrants\n",
    "   \n",
    "    def GetBestFitIndividual(self) -> Individual:\n",
    "        return min( self.population, key=getFitness )\n",
    "    \n",
    "    def GetWorstFitIndividual(self) -> Individual:\n",
    "        return max( self.population, key=getFitness )\n",
    "   \n",
    "    def GetBestFitness(self) -> float:\n",
    "        return self.GetBestFitIndividual().fitness\n",
    "    \n",
    "    def GetWorstFitness(self) -> float:\n",
    "        return self.GetWorstFitIndividual().fitness\n",
    "    \n",
    "    def GetAvgFitness(self) -> float:\n",
    "        fitnessSum = 0\n",
    "        for i in range(0, len(self.population)):\n",
    "            #take the fitness sum\n",
    "            fitnessSum +=  self.population[i].fitness\n",
    "        \n",
    "        return fitnessSum / self.populationSize\n",
    "    \n",
    "    def Crossover(self, parent1: Individual, parent2: Individual, xrate: float = 1) -> tuple:\n",
    "        \"\"\"Swaps subtree parents at their xpoints. \n",
    "        Xpoints gauss centered around last leaf.\n",
    "        Never chooses the root node to do crossover with.\n",
    "\n",
    "        Args:\n",
    "            parent1 (Individual): _description_\n",
    "            parent2 (Individual): _description_\n",
    "\n",
    "        Returns:\n",
    "            tuple: child1, child2, whether xover happened\n",
    "        \"\"\"\n",
    "        \n",
    "        #clone children from parents\n",
    "        child1 = parent1.copy() \n",
    "        child2 = parent2.copy() \n",
    "        \n",
    "        #roll on whether to do crossover\n",
    "        randProb = np.random.random()\n",
    "        xover = randProb <= xrate\n",
    "        if( xover ):\n",
    "        \n",
    "            #pick crossover point\n",
    "            xpoint = random.randint(1, len(parent1.genes)-2)\n",
    "            \n",
    "            #swap parent genes at xpoint\n",
    "            child1.genes = parent1.genes[:xpoint] + parent2.genes[xpoint:]\n",
    "            child2.genes = parent2.genes[:xpoint] + parent1.genes[xpoint:]\n",
    "\n",
    "        return child1, child2, xover\n",
    "    \n",
    "    def SelectParents(self) -> tuple:\n",
    "        xIndexRange, prob = self.SetupHalfNormIntDistr(self.populationSize, stdDev=self.populationSize/3)\n",
    "    \n",
    "        #if overloaded to display distr graph\n",
    "        if(False):\n",
    "            #take randos using the calc'd prob and index range\n",
    "            nums = np.random.choice(xIndexRange, size = 1000000, p = prob)\n",
    "            #display distr histogram\n",
    "            plt.rcParams.update({'font.size': 22})\n",
    "            plt.hist(nums, bins = pop_size)\n",
    "            plt.title(\"likelihood of each parent index being chosen\")\n",
    "            plt.ylabel(\"likelihood of being chosen\")\n",
    "            plt.xlabel(\"parent index\")\n",
    "            plt.show()\n",
    "\n",
    "        #get parent indices\n",
    "        parent1Index, parent2Index = np.random.choice(xIndexRange, size = 2, p = prob)\n",
    "        #parent1Index, parent2Index = parentIndices[0], parentIndices[1]\n",
    "        \n",
    "        #make sure indices within array range\n",
    "        #assert parent1Index < self.populationSize and parent2Index < self.populationSize and type(parent1Index) == int and type(parent2Index) == int\n",
    "    \n",
    "        return self.population[int(parent1Index)], self.population[int(parent2Index)]\n",
    "    \n",
    "    def SetupHalfNormIntDistr(self, pop_size: int, stdDev: int) -> tuple:\n",
    "        \"\"\"\n",
    "        The half normal integer distribution parent indices are drawn from.\n",
    "\n",
    "        Returns:\n",
    "            tuple: index range and probability funct\n",
    "        \"\"\"\n",
    "        #take interval 1-100\n",
    "        x = np.arange(1, pop_size+1) #bc upper bound is exclusive\n",
    "        #store every number's +/-0.5\n",
    "        xU, xL = x + 0.5, x - 0.5 \n",
    "        #determine probability\n",
    "        prob = ss.halfnorm.cdf(xU, scale = stdDev) - ss.halfnorm.cdf(xL, scale = stdDev) #scale represents inner quartiles\n",
    "        prob = prob / prob.sum() # normalize the probabilities so their sum is 1\n",
    "        #decr by 1 to find the index 0-99\n",
    "        xIndexRange = x - 1\n",
    "    \n",
    "        return xIndexRange, prob\n",
    "    \n",
    "    def OrderPopulationByFitness(self):\n",
    "        #sort in descending order\n",
    "        self.population.sort(key=getFitness)\n",
    "    \n",
    "    def PlotGenerationalFitness(self):\n",
    "        t = np.arange(0, self.currentGeneration+1)\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 22})\n",
    "        plt.title('Generational Fitness Data')\n",
    "        plt.plot(t, self.worstFitness, label='Worst Fitness') \n",
    "        plt.plot(t, self.avgFitness, label='Average Fitness') \n",
    "        plt.plot(t, self.bestFitness, label='Best Fitness') \n",
    "        plt.grid() \n",
    "        plt.legend()\n",
    "        plt.ylabel('Fitness')\n",
    "        plt.xlabel('Generation')\n",
    "        \n",
    "        #init worst worst fit\n",
    "        worstWorstFitness = max(self.worstFitness)\n",
    "        \n",
    "        fitnessIndex = 0\n",
    "        \n",
    "        for fitnessData in (self.worstFitness, self.avgFitness, self.bestFitness):\n",
    "            yAnnotatePosition = worstWorstFitness - worstWorstFitness * fitnessIndex / 12\n",
    "            \n",
    "            fitnessIndex += 1\n",
    "            \n",
    "            plt.annotate('%0.7f' % min(fitnessData), xy=(1, yAnnotatePosition), xytext=(8, 0), \n",
    "                        xycoords=('axes fraction', 'data'), textcoords='offset points')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def Test(self, x, y, testType: TestType):\n",
    "        \n",
    "        inputCount = len(x)\n",
    "        \n",
    "        outputCount = len(y)\n",
    "        \n",
    "        assert inputCount == outputCount\n",
    "        \n",
    "        #for i in range(self.populationSize): #why re-eval fitness for new data??\n",
    "        #    self.population[i].EvaluateFitness(x, y)\n",
    "            \n",
    "        bestFitIndividual = self.GetBestFitIndividual()\n",
    "        \n",
    "        #print(\"Best fit individual:\")\n",
    "        #print(anytree.RenderTree(bestFitIndividual.root))\n",
    "        \n",
    "        y_pred = bestFitIndividual.Predict(x)\n",
    "        \n",
    "        assert len(y_pred) == outputCount\n",
    "        \n",
    "        accuracy = sum( y_pred == y ) / outputCount\n",
    "        \n",
    "        #remember this gp's performance\n",
    "        if testType == TestType.TEST:\n",
    "            self.testPerformance = accuracy\n",
    "        else:\n",
    "            self.trainingPerformance = accuracy\n",
    "        \n",
    "        print(f\"{testType} Accuracy: {accuracy}\")\n",
    "        \n",
    "        t = np.arange(0, outputCount)\n",
    "        \n",
    "        plt.rcParams.update({'font.size': 22})\n",
    "        plt.plot(t, y_pred, label='Predictions') \n",
    "        plt.plot(t, y, label='Targets') \n",
    "        #plt.hist(y, label='Predictions')\n",
    "        #plt.hist(y_pred, label='Targets')\n",
    "        plt.legend()\n",
    "        plt.grid() \n",
    "        plt.title(f'{testType} Predictions vs Targets')\n",
    "        plt.ylabel('y')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylim(-1, 2)\n",
    "        plt.show()\n",
    "    \n",
    "    def __str__(self):  \n",
    "        return f\"GP best fitness = {self.bestFitness[-1]}; GP training performance = {self.trainingPerformance}; GP test performance = {self.testPerformance};\"\n",
    "\n",
    "test_x_train = x_train[0:5]\n",
    "test_y_train = y_train[0:5]\n",
    "test_x_test = x_test[0:5]\n",
    "test_y_test = y_test[0:5]\n",
    "    \n",
    "#test GA\n",
    "ga = GA(\n",
    "    populationSize=30,\n",
    "    model=model,\n",
    "    xrate=0.9,\n",
    "    x_train=test_x_train,\n",
    "    y_train=test_y_train,\n",
    "    pairs_of_parents_elitism_saves=1,\n",
    "    #migration_size=10\n",
    ")\n",
    "\n",
    "ga.RunGen()\n",
    "\n",
    "print(ga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 20 #40 \n",
    "GENERATIONS_PER_RUN = 30 #60\n",
    "PAIRS_OF_PARENTS_SAVED_FOR_ELITISM = 1\n",
    "XRATE = 0.95\n",
    "INIT_DEPTH = 4\n",
    "ISLANDS = 5\n",
    "MIGRATION_INTERVAL = 5\n",
    "MIGRATION_SIZE = 10\n",
    "ISLAND_MODEL = True\n",
    "ALGORITHM_ITERATIONS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "{'values_changed': {'root[0][68][53]': {'new_value': 0.5887725942022416, 'old_value': 0.7463842333662047}}}\n",
      "{'values_changed': {'root[0][163][54]': {'new_value': 0.6878869160215382, 'old_value': 0.24541228628912387}}}\n",
      "{'values_changed': {'root[0][136][44]': {'new_value': 0.740919010922955, 'old_value': 0.7759089420985774}}}\n",
      "{'values_changed': {'root[0][162][37]': {'new_value': 0.6287210856538447, 'old_value': 0.777583328498058}}}\n",
      "{'values_changed': {'root[0][281][1]': {'new_value': 0.2499021352790488, 'old_value': 0.5352532890711618}}}\n",
      "{'values_changed': {'root[0][170][4]': {'new_value': 0.5056162880715303, 'old_value': 0.25200245028100937}}}\n",
      "{'values_changed': {'root[0][263][55]': {'new_value': 0.5405217191472682, 'old_value': 0.9664055601919073}}}\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[39m#run every island for a gen\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(ISLANDS):\n\u001b[1;32m---> 45\u001b[0m         islands[j]\u001b[39m.\u001b[39;49mRunGen()\n\u001b[0;32m     47\u001b[0m \u001b[39m#every island \u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(ISLANDS):\n",
      "Cell \u001b[1;32mIn [16], line 84\u001b[0m, in \u001b[0;36mGA.RunGen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbestFitness\u001b[39m.\u001b[39mappend( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGetBestFitness() )\n\u001b[0;32m     83\u001b[0m \u001b[39m#create new pop\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mCreateNextGeneration()\n\u001b[0;32m     86\u001b[0m \u001b[39m#store newly created pops fitness fields\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgFitness\u001b[39m.\u001b[39mappend( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGetAvgFitness() ) \n",
      "Cell \u001b[1;32mIn [16], line 110\u001b[0m, in \u001b[0;36mGA.CreateNextGeneration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39m#walk thru half pop\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpairs_of_parents_elitism_saves, pairs_of_children):\n\u001b[0;32m    109\u001b[0m     \u001b[39m#select parents\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     parent1, parent2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelectParents()\n\u001b[0;32m    111\u001b[0m     \u001b[39m#do crossover\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     child1, child2, xover \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCrossover(parent1, parent2, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxrate)\n",
      "Cell \u001b[1;32mIn [16], line 220\u001b[0m, in \u001b[0;36mGA.SelectParents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    214\u001b[0m parent1Index, parent2Index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(xIndexRange, size \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, p \u001b[39m=\u001b[39m prob)\n\u001b[0;32m    215\u001b[0m \u001b[39m#parent1Index, parent2Index = parentIndices[0], parentIndices[1]\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \n\u001b[0;32m    217\u001b[0m \u001b[39m#make sure indices within array range\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m#assert parent1Index < self.populationSize and parent2Index < self.populationSize and type(parent1Index) == int and type(parent2Index) == int\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation[\u001b[39mint\u001b[39m(parent1Index)], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpopulation[\u001b[39mint\u001b[39;49m(parent2Index)]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#shrink datatset for faster training\n",
    "x_train_subset = x_train[0:10] #[0:10] = 3 minute runtime, [0:30] = 8 minute runtime\n",
    "y_train_subset = y_train[0:10]\n",
    "\n",
    "for i in range(ALGORITHM_ITERATIONS): \n",
    "    \n",
    "    if ISLAND_MODEL:\n",
    "\n",
    "        islands = np.empty(ISLANDS, dtype=GA)\n",
    "        \n",
    "        #create all islands\n",
    "        for j in range(ISLANDS):\n",
    "            islands[j] = GA(\n",
    "                populationSize=POPULATION_SIZE,\n",
    "                model=model,\n",
    "                xrate=XRATE,\n",
    "                x_train=x_train_subset,\n",
    "                y_train=y_train_subset,\n",
    "                pairs_of_parents_elitism_saves=PAIRS_OF_PARENTS_SAVED_FOR_ELITISM,\n",
    "                migration_size=MIGRATION_SIZE,\n",
    "                migration_interval=MIGRATION_INTERVAL\n",
    "            )\n",
    "            \n",
    "         #each generation\n",
    "        for k in range(GENERATIONS_PER_RUN):\n",
    "            \n",
    "            #if on migration interval\n",
    "            if k % MIGRATION_INTERVAL == 0:\n",
    "                #pass migration pop tween islands\n",
    "                for j in range(ISLANDS):\n",
    "                    #get island's migrants\n",
    "                    migrants = islands[j].GetMigrants()\n",
    "                    #if didn't just get immigrants from last island\n",
    "                    if j != ISLANDS-1:\n",
    "                        #pass migrants to next island\n",
    "                        islands[j+1].RecvMigrants(migrants)\n",
    "                    #if just got immigrants from last island\n",
    "                    else: \n",
    "                        #pass migrants to 1st island\n",
    "                        islands[0].RecvMigrants(migrants)\n",
    "            \n",
    "            #run every island for a gen\n",
    "            for j in range(ISLANDS):\n",
    "                \n",
    "                islands[j].RunGen()\n",
    "                \n",
    "        #every island \n",
    "        for j in range(ISLANDS):\n",
    "            \n",
    "            islandGP = islands[j]\n",
    "            \n",
    "            #if 1st island of 1st iteration, or curr gp performs better than prev best\n",
    "            if( \n",
    "               (i == 0 and j == 0) or \n",
    "               islandGP.bestFitness[-1] < bestIslandFitness\n",
    "            ):\n",
    "                #make it the best\n",
    "                bestIslandFitness = islandGP.bestFitness[-1]\n",
    "                bestIsland = islandGP\n",
    "        \n",
    "        gp = bestIsland\n",
    "        \n",
    "    else:\n",
    "        ga = GA(\n",
    "            populationSize=POPULATION_SIZE,\n",
    "            model=model,\n",
    "            xrate=XRATE,\n",
    "            x_train=x_train_subset,\n",
    "            y_train=y_train_subset,\n",
    "            pairs_of_parents_elitism_saves=PAIRS_OF_PARENTS_SAVED_FOR_ELITISM,\n",
    "        )\n",
    "        \n",
    "        for _ in range(GENERATIONS_PER_RUN):\n",
    "        \n",
    "            ga.RunGen()\n",
    "\n",
    "        #if first GP or curr gp performs better than prev best\n",
    "        if( i == 0 or ga.bestFitness[-1] < bestGAFitness):\n",
    "            #make it the best\n",
    "            bestGAFitness = ga.bestFitness[-1]\n",
    "            bestGA = ga\n",
    "            \n",
    "    print(bestGA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test accuracy\n",
    "y_test_pred = model.predict(x_test)[:, 0] #cutoff last dim bc useless\n",
    "truePreds = np.sum(y_test == y_test_pred)\n",
    "test_acc = truePreds / y_test.shape[0]\n",
    "\n",
    "print(f'test accuracy: {test_acc * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history of training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training acc', 'validation acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get access to filters/kernels\n",
    "weights = hiddenLayers[0].get_weights()[0][:, :, 0, :] #arr of a buncha nested lists, 0 bc only have 1 channel (28, 28, 1, 8)\n",
    "\n",
    "#can get access to other params this way \n",
    "\n",
    "for i in range(1, 8):\n",
    "    plt.subplot(2, 4, i)\n",
    "    plt.imshow(weights[:,:,i], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "#how get access to feature maps?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('EvoComp': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe32189b82d98f8d4c6c56307210a678aeb8b7128cbceacf7b4eb9894a56bcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
